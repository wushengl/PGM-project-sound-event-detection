{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wushengl/PGM-project-sound-event-detection/blob/main/YOHO_upgraded_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9sygNYmHLwT"
      },
      "source": [
        "# 1. Install and Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-MMqvzgHBl7",
        "outputId": "497620ae-86a1-4738-cccc-fc20a0c2fef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SpecAugment'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Total 271 (delta 0), reused 0 (delta 0), pack-reused 271\u001b[K\n",
            "Receiving objects: 100% (271/271), 429.45 KiB | 8.59 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./SpecAugment\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from SpecAugment==1.2.3) (2.12.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from SpecAugment==1.2.3) (0.10.0.post2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from SpecAugment==1.2.3) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from SpecAugment==1.2.3) (2.0.0+cu118)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.2.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.0.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (4.5.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.22.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (0.12.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (0.3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.2.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (4.4.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (1.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->SpecAugment==1.2.3) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (23.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SpecAugment==1.2.3) (8.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (1.6.3)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (0.4.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (0.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (23.3.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (0.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (3.20.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (2.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (3.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (2.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (2.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (1.54.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (67.7.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->SpecAugment==1.2.3) (16.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->SpecAugment==1.2.3) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->SpecAugment==1.2.3) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->SpecAugment==1.2.3) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->SpecAugment==1.2.3) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->SpecAugment==1.2.3) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->SpecAugment==1.2.3) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->SpecAugment==1.2.3) (16.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->SpecAugment==1.2.3) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->SpecAugment==1.2.3) (0.1.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->SpecAugment==1.2.3) (0.39.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (2.27.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->SpecAugment==1.2.3) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->SpecAugment==1.2.3) (1.15.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (2.17.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->SpecAugment==1.2.3) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->SpecAugment==1.2.3) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->SpecAugment==1.2.3) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->SpecAugment==1.2.3) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->SpecAugment==1.2.3) (3.2.2)\n",
            "Building wheels for collected packages: SpecAugment\n",
            "  Building wheel for SpecAugment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SpecAugment: filename=SpecAugment-1.2.3-py3-none-any.whl size=16695 sha256=b4b1bd327e393c56b6476182a7123d792a2b5f54ecce5ca443150c2de73eda28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-afpnaah6/wheels/2a/3f/22/b1010812c6f4e7022aa188158ac89f91f71028dbda2f35e740\n",
            "Successfully built SpecAugment\n",
            "Installing collected packages: SpecAugment\n",
            "Successfully installed SpecAugment-1.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.32.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sed_eval\n",
            "  Downloading sed_eval-0.2.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sed_eval) (1.22.4)\n",
            "Collecting dcase_util>=0.2.4\n",
            "  Downloading dcase_util-0.2.20.tar.gz (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.7.1)\n",
            "Requirement already satisfied: librosa>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.10.0.post2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.16.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.18.3)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (6.0)\n",
            "Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (4.65.0)\n",
            "Requirement already satisfied: pydot-ng>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.0.0)\n",
            "Collecting validators>=0.12.0\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic>=0.4.13\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.3.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (4.4.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (3.0.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.56.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.2.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (0.11.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (1.26.15)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (2.21)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (67.7.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (3.1.0)\n",
            "Building wheels for collected packages: sed_eval, dcase_util, validators\n",
            "  Building wheel for sed_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sed_eval: filename=sed_eval-0.2.1-py3-none-any.whl size=26121 sha256=d5f3c5e761ed541ad97b84d69e65834ac414da4f1af92e7a156debd484a81659\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/a5/72/8e29db552a620b55434766ea7a4cfc7a08f93a4bd226a5bb38\n",
            "  Building wheel for dcase_util (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dcase_util: filename=dcase_util-0.2.20-py3-none-any.whl size=2164607 sha256=4dde70e4c62554e3a0e18d8ca18dd88e1ff3715dfae4b4ee5a0cdeb03b3d67c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/33/01/ff8f027eb9a938cd294b41c33e502e3deceb60ec394183769d\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=48138bf7e0ca70bea43e27a8b572d117332e5df7d2ba596b51d040b4fc74bbc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built sed_eval dcase_util validators\n",
            "Installing collected packages: validators, python-magic, dcase_util, sed_eval\n",
            "Successfully installed dcase_util-0.2.20 python-magic-0.4.27 sed_eval-0.2.1 validators-0.20.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DemisEom/SpecAugment.git\n",
        "!pip install /content/SpecAugment/\n",
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow-io\n",
        "!pip install sed_eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2wttNJWHXgM",
        "outputId": "46ca2997-cc6f-4011-efc2-b1830f13737e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import csv\n",
        "import random\n",
        "import os.path\n",
        "import pdb\n",
        "\n",
        "import re\n",
        "import glob\n",
        "import shutil\n",
        "import librosa\n",
        "import keras\n",
        "import sed_eval\n",
        "import dcase_util\n",
        "import pickle\n",
        "\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "from subprocess import Popen, PIPE\n",
        "from os.path import dirname\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from SpecAugment import spec_augment_tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcMwka2oIuJh"
      },
      "source": [
        "# 2. Download Dataset and Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJHQG34rIBQD"
      },
      "source": [
        "## 2.1 Preparing .npy dataset and Google drive \n",
        "\n",
        "- downloaded dataset are preprocessed log melspectrograms \n",
        "  - data size: (1001,40)\n",
        "  - label size: (32,30)\n",
        "- To download the original Urban-SED dataset by Salamon et al., visit this [page](http://urbansed.weebly.com/). Ensure the dataset is saved into /content/Urban-SED-V2.tar.gz. (**We've already downloaded the original dataset and uploaded to shared drive**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Phzc5d3IDSx",
        "outputId": "1827342e-39b8-42c0-ecd8-80855f9a5b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3jEalL5IMzX",
        "outputId": "c0dbbd3b-b120-4043-86b3-e5de537c2415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-27 18:05:23--  https://docs.google.com/uc?export=download&confirm=t&id=19vTnCCNrfh1mUsVzTBKQEDpjpHwveTXQ\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.210.139, 173.194.210.113, 173.194.210.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.210.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mh3rff2kltddbjm8ivb4kgmnkitsacv6/1682618700000/04739181468756608208/*/19vTnCCNrfh1mUsVzTBKQEDpjpHwveTXQ?e=download&uuid=999b51e4-98a0-4170-973a-5041f65304ac [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-27 18:05:23--  https://doc-08-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mh3rff2kltddbjm8ivb4kgmnkitsacv6/1682618700000/04739181468756608208/*/19vTnCCNrfh1mUsVzTBKQEDpjpHwveTXQ?e=download&uuid=999b51e4-98a0-4170-973a-5041f65304ac\n",
            "Resolving doc-08-6k-docs.googleusercontent.com (doc-08-6k-docs.googleusercontent.com)... 173.194.212.132, 2607:f8b0:400c:c11::84\n",
            "Connecting to doc-08-6k-docs.googleusercontent.com (doc-08-6k-docs.googleusercontent.com)|173.194.212.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1971199582 (1.8G) [application/zip]\n",
            "Saving to: ‘train-data.zip’\n",
            "\n",
            "train-data.zip      100%[===================>]   1.83G   115MB/s    in 19s     \n",
            "\n",
            "2023-04-27 18:05:42 (101 MB/s) - ‘train-data.zip’ saved [1971199582/1971199582]\n",
            "\n",
            "--2023-04-27 18:05:42--  https://docs.google.com/uc?export=download&confirm=t&id=1-0SZavmwJI7zB8734_uek0ejLUTaa1M7\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.210.139, 173.194.210.113, 173.194.210.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.210.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rllgrq5gjqsn0k7k2q9t4ubv83mks48r/1682618700000/04739181468756608208/*/1-0SZavmwJI7zB8734_uek0ejLUTaa1M7?e=download&uuid=9bc659a8-b782-440f-af6a-1c6a017e5522 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-27 18:05:43--  https://doc-08-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rllgrq5gjqsn0k7k2q9t4ubv83mks48r/1682618700000/04739181468756608208/*/1-0SZavmwJI7zB8734_uek0ejLUTaa1M7?e=download&uuid=9bc659a8-b782-440f-af6a-1c6a017e5522\n",
            "Resolving doc-08-6k-docs.googleusercontent.com (doc-08-6k-docs.googleusercontent.com)... 173.194.212.132, 2607:f8b0:400c:c11::84\n",
            "Connecting to doc-08-6k-docs.googleusercontent.com (doc-08-6k-docs.googleusercontent.com)|173.194.212.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 657047582 (627M) [application/zip]\n",
            "Saving to: ‘val-data.zip’\n",
            "\n",
            "val-data.zip        100%[===================>] 626.61M   124MB/s    in 5.9s    \n",
            "\n",
            "2023-04-27 18:05:49 (106 MB/s) - ‘val-data.zip’ saved [657047582/657047582]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=19vTnCCNrfh1mUsVzTBKQEDpjpHwveTXQ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=19vTnCCNrfh1mUsVzTBKQEDpjpHwveTXQ\" -O train-data.zip && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-0SZavmwJI7zB8734_uek0ejLUTaa1M7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-0SZavmwJI7zB8734_uek0ejLUTaa1M7\" -O val-data.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzLbJCy7IVUO"
      },
      "outputs": [],
      "source": [
        "# extract zip files for both train and validation data \n",
        "zip_name0 = \"/content/train-data.zip\"\n",
        "with ZipFile(zip_name0, 'r') as zip:\n",
        "  zip.extractall()\n",
        "\n",
        "zip_name1 = \"/content/val-data.zip\"\n",
        "with ZipFile(zip_name1, 'r') as zip:\n",
        "  zip.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B27_aDcIXUW",
        "outputId": "04bd67bd-88cf-4b79-ffd6-5fb347c7581a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12000\n",
            "6000\n",
            "4000\n",
            "2000\n"
          ]
        }
      ],
      "source": [
        "print(len(glob.glob(\"/content/content/train-data/*.npy\")))\n",
        "print(len(glob.glob(\"/content/content/train-data/label-*.npy\")))\n",
        "print(len(glob.glob(\"/content/content/val-data/*.npy\")))\n",
        "print(len(glob.glob(\"/content/content/val-data/label-*.npy\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_vw0OyYLHrm"
      },
      "source": [
        "## 2.2 Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJt9IlFmLKbK"
      },
      "outputs": [],
      "source": [
        "# Function for constructing list of audio frames and window ranges from original dataset audio file \n",
        "def construct_examples(audio_path, win_len = 2.56, hop_len = 1.0, sr = 44100.0):\n",
        "\n",
        "  win_len_t = win_len\n",
        "  hop_len_t = hop_len\n",
        "\n",
        "  win_len = int(sr*win_len)\n",
        "  hop_len = int(sr*hop_len)\n",
        "\n",
        "  a, sr = sf.read(audio_path)\n",
        "\n",
        "  if a.shape[0] < win_len:\n",
        "    a_padded = np.zeros((win_len, ))\n",
        "    a_padded[0:a.shape[0]] = a  \n",
        "\n",
        "  else:\n",
        "    no_of_hops = math.ceil((a.shape[0] - win_len) / hop_len)\n",
        "    a_padded = np.zeros((int(win_len + hop_len*no_of_hops), ))\n",
        "    a_padded[0:a.shape[0]] = a  \n",
        "\n",
        "  a_ex = [a_padded[i - win_len : i] for i in range(win_len, a_padded.shape[0]+1, hop_len)]\n",
        "  print([i - win_len for i in range(win_len, a_padded.shape[0]+1, hop_len)])\n",
        "  win_ranges = [((i - win_len)/sr, i/sr) for i in range(win_len, a_padded.shape[0]+1, hop_len)]\n",
        "\n",
        "  return a_ex, win_ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MFCpuksLRU8"
      },
      "outputs": [],
      "source": [
        "def get_log_melspectrogram(audio, sr = 44100, hop_length = 441, win_length = 1764, n_fft = 2048, n_mels = 40, fmin = 0, fmax = 22050):\n",
        "    \"\"\"Return the log-scaled Mel bands of an audio signal.\"\"\"\n",
        "    audio_2 = librosa.util.normalize(audio)\n",
        "    bands = librosa.feature.melspectrogram(\n",
        "        y=audio_2, sr=sr, hop_length=hop_length, win_length = win_length, n_fft=n_fft, n_mels=n_mels)\n",
        "    return librosa.core.power_to_db(bands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCHA61z5LW5y"
      },
      "outputs": [],
      "source": [
        "class_dict = {'air_conditioner': 0,\n",
        "        'car_horn': 1,\n",
        "        'children_playing': 2,\n",
        "        'dog_bark': 3,\n",
        "        'drilling': 4,\n",
        "        'engine_idling': 5,\n",
        "        'gun_shot': 6,\n",
        "        'jackhammer': 7,\n",
        "        'siren': 8,\n",
        "        'street_music': 9}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIbpfEDKLXof"
      },
      "outputs": [],
      "source": [
        "# Function for reading events from txt files in original dataset label file \n",
        "def read_annotation(filename):\n",
        "    events = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        spamreader = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
        "        for row in spamreader:\n",
        "            events.append(row)\n",
        "    return events\n",
        "    \n",
        "# Test function\n",
        "# events = read_annotation(\"/content/Urban-SED/URBAN-SED_v2.0.0/annotations/train/soundscape_train_bimodal0.txt\")\n",
        "# events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfKI_KIbLmRC"
      },
      "outputs": [],
      "source": [
        "def construct_labels(annotation_path, win_start, win_end, win_len):\n",
        "  events = read_annotation(annotation_path)\n",
        "\n",
        "  ann = [[float(e[0]), float(e[1]), e[2]] for e in events]\n",
        "\n",
        "  curr_ann = []\n",
        "\n",
        "  for a in ann:\n",
        "    if a[1] > win_start and a[0] <= win_end: \n",
        "    # if a[0] >= win_start and a[0] < win_end:\n",
        "      curr_start = max(a[0] - win_start, 0.0)\n",
        "      curr_end = min(a[1] - win_start, win_len)\n",
        "      curr_ann.append([curr_start, curr_end, a[2]])    \n",
        "\n",
        "  class_set = set([c[2] for c in curr_ann])\n",
        "  class_wise_events = {}\n",
        "\n",
        "  for c in list(class_set):\n",
        "    class_wise_events[c] = []\n",
        "\n",
        "\n",
        "  for c in curr_ann:\n",
        "    class_wise_events[c[2]].append(c)\n",
        "    \n",
        "  max_event_silence = 0.0\n",
        "  all_events = []\n",
        "\n",
        "  for k in list(class_wise_events.keys()):\n",
        "    curr_events = class_wise_events[k]\n",
        "    count = 0\n",
        "\n",
        "    while count < len(curr_events) - 1:\n",
        "      if (curr_events[count][1] >= curr_events[count + 1][0]) or (curr_events[count + 1][0] - curr_events[count][1] <= max_event_silence):\n",
        "        curr_events[count][1] = max(curr_events[count + 1][1], curr_events[count][1])\n",
        "        del curr_events[count + 1]\n",
        "      else:\n",
        "        count += 1\n",
        "\n",
        "    all_events += curr_events\n",
        "\n",
        "  for i in range(len(all_events)):\n",
        "    all_events[i][0] = round(all_events[i][0], 3)\n",
        "    all_events[i][1] = round(all_events[i][1], 3)\n",
        "\n",
        "  all_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return all_events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Epc2ytuLp1C"
      },
      "outputs": [],
      "source": [
        "def to_seg_by_class(events, class_dict, hop_len = 441, n_frames = 1001, sr=44100):\n",
        "  # events = smoothe_events(events)\n",
        "  labels = np.zeros((n_frames, 10), dtype=np.float32)\n",
        "\n",
        "  for e in events:\n",
        "    t1 = float(e[0])\n",
        "    t1 = int(t1 / hop_len * sr)\n",
        "    t2 = float(e[1])\n",
        "    t2 = int(t2 / hop_len * sr)\n",
        "\n",
        "    labels[t1:t2, class_dict[e[2]]] = 1    \n",
        "  \n",
        "  return labels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4m8F7s3LrZC"
      },
      "outputs": [],
      "source": [
        "def get_universal_labels(events, class_dict, ex_length = 10.0, no_of_div = 32):\n",
        "  win_length = ex_length/no_of_div\n",
        "  labels = np.zeros((no_of_div, len(class_dict.keys()) * 3))\n",
        "  \n",
        "  for e in events:\n",
        "\n",
        "    start_time = float(e[0])\n",
        "    stop_time = float(e[1])\n",
        "\n",
        "    start_bin = int(start_time // win_length)\n",
        "    stop_bin = int(stop_time // win_length)\n",
        "\n",
        "    start_time_2 = start_time - start_bin * win_length\n",
        "    stop_time_2 = stop_time - stop_bin * win_length\n",
        "\n",
        "    n_bins = stop_bin - start_bin\n",
        "\n",
        "    if n_bins == 0:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, stop_time_2]    \n",
        "\n",
        "    elif n_bins == 1:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        labels[stop_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "    elif n_bins > 1:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, win_length]\n",
        "\n",
        "      for i in range(1, n_bins):\n",
        "        labels[start_bin + i, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        labels[stop_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "  # labels[:, [1, 2, 4, 5]] /= win_length\n",
        "\n",
        "  for i in range(len(labels)):\n",
        "    for j in range(len(labels[i])):\n",
        "      if j % 3 != 0:\n",
        "        labels[i][j] /= win_length\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-2oCF4zI49s"
      },
      "source": [
        "## 2.3 Preparing the dataset from the URBAN-SED website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JavuOtD4JCea"
      },
      "outputs": [],
      "source": [
        "#os.mkdir(\"/content/Urban-SED/\")\n",
        "# unzipping the original dataset, if need to run, make sure the paths are correct and the folders exist \n",
        "zip_name = \"/content/drive/MyDrive/10708 - Project/code/URBAN-SED_v2.0.0.tar.gz\"\n",
        "shutil.unpack_archive(zip_name, \"/content/Urban-SED/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_t5-4HmK6p-",
        "outputId": "0fcccc95-05e2-4df0-ee36-767da41ce365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6000\n",
            "6000\n"
          ]
        }
      ],
      "source": [
        "# make file list for train and validation dataset from original dataset \n",
        "\n",
        "train_files = glob.glob(\"/content/Urban-SED/URBAN-SED_v2.0.0/audio/train/*.wav\")\n",
        "val_files = glob.glob(\"/content/Urban-SED/URBAN-SED_v2.0.0/audio/validate/*.wav\")\n",
        "\n",
        "train_ann = glob.glob(\"/content/Urban-SED/URBAN-SED_v2.0.0/annotations/train/*.txt\")\n",
        "val_ann = glob.glob(\"/content/Urban-SED/URBAN-SED_v2.0.0/annotations/validate/*.txt\")\n",
        "\n",
        "# if not os.path.exists(\"/content/original-data/\"):\n",
        "#   os.mkdir(\"/content/original-data/\")\n",
        "# test the files\n",
        "print(len(train_files))# = 6000\n",
        "print(len(train_ann))# = 6000\n",
        "# sampling rate: 44100\n",
        "# sample length: 10s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-1q09dJeHwd",
        "outputId": "ad7e3f4a-0541-43fd-b417-8b5bf41db84f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Urban-SED/URBAN-SED_v2.0.0/audio/train/soundscape_train_bimodal954.wav'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_files[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHdZeLRLenLI",
        "outputId": "dba4512c-0252-4a7f-bc77-038c1c17b226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1001, 40)\n"
          ]
        }
      ],
      "source": [
        "zzz = np.load(\"/content/content/train-data/ex-0.npy\")\n",
        "print(zzz.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZgdmntjNGJF"
      },
      "source": [
        "# 3. Dataloader: creating the data-label pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2isrIrrANPR3"
      },
      "source": [
        "## 3.1 Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ELweTdNLnZ"
      },
      "outputs": [],
      "source": [
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "    \n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afhZYjCvNXE1"
      },
      "source": [
        "## 3.2 Loading .npy datasets into partitions\n",
        "- load data from saved mel-spectrogram and labels\n",
        "- save into \"partition\" which contains both training and validation data\n",
        "- len(partition['train']) = 6000\n",
        "- len(partition['validation']) = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1AGFloUNnZK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Load the individual numpy arrays into partition\n",
        "\"\"\"\n",
        "data = glob.glob(\"/content/content/train-data/ex-*.npy\") # + glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "#data = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/content/train-data/label-*.npy\") #+ glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "#labels = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "train_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(train_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf0Yd3vAN1Gc",
        "outputId": "1b95ceaf-d8fe-4f92-a416-6e394439fffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('/content/content/val-data/ex-1211.npy', '/content/content/val-data/label-1211.npy')\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This loads data for the validation set.\n",
        "\"\"\"\n",
        "data = glob.glob(\"/content/content/val-data/ex-*.npy\")\n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/content/val-data/label-*.npy\")\n",
        "sort_nicely(labels)\n",
        "\n",
        "validation_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(validation_examples)\n",
        "print(validation_examples[0])\n",
        "\n",
        "# m = len(test_examples)\n",
        "# m_validation = 1024\n",
        "# m_test = 512\n",
        "# m_train = m - m_validation - m_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6eA4AaBNvq9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Creating the train & validation partition.\n",
        "\"\"\"\n",
        "partition = {}\n",
        "partition['train'] = train_examples\n",
        "random.shuffle(partition['train'])\n",
        "partition['validation'] = validation_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOy8OikeOj1j"
      },
      "source": [
        "## 3.3 DataGenerator #1: y size (32,30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2ZmPn2uOY7_"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_examples, batch_size=128, epoch_size = 16384, dim=(1, ),\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        print(\"Constructor called!!!\")\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch_size = epoch_size\n",
        "        self.list_examples = list_examples\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        #print(\"The self.list_examples is {}\".format(self.list_examples))\n",
        "        return int(np.floor(len(self.list_examples) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_examples[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "      self.indexes = np.arange(len(self.list_examples))\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # 'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # # Initialization\n",
        "        #X = np.empty([self.batch_size, 1001, 40, 1], dtype=np.float64)\n",
        "        X = np.empty([self.batch_size, 1001, 40], dtype=np.float64)\n",
        "        y = np.empty([self.batch_size, 32, 30], dtype=np.float64) # 1001,10\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "          # Store sample\n",
        "\n",
        "          xx = np.load(ID[0])\n",
        "\n",
        "          # v = xx.shape[0]\n",
        "          # tau = xx.shape[1]\n",
        "\n",
        "          # xx = tf.expand_dims(xx, axis=0)\n",
        "          # xx = tf.expand_dims(xx, axis=-1)\n",
        "\n",
        "          # # warped_mel_spectrogram = sparse_warp(mel_spectrogram)\n",
        "\n",
        "          # warped_frequency_spectrogram = spec_augment_tensorflow.frequency_masking(xx, v=v, frequency_masking_para=8, frequency_mask_num=1)\n",
        "\n",
        "          # warped_frequency_time_sepctrogram = spec_augment_tensorflow.time_masking(warped_frequency_spectrogram, tau=tau, time_masking_para=25, time_mask_num=2)\n",
        "\n",
        "          \n",
        "\n",
        "          # xx = tf.expand_dims(xx, axis=0)\n",
        "          # xx = tf.expand_dims(xx, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "          # freq_mask = tfio.audio.freq_mask(xx, param=8)\n",
        "\n",
        "          # time_mask = tfio.audio.time_mask(freq_mask, param=25)\n",
        "\n",
        "          # xx = tf.squeeze(warped_frequency_time_sepctrogram)\n",
        "          X[i, :, :] = xx\n",
        "\n",
        "          # Store class\n",
        "          yy = np.load(ID[1])\n",
        "          # yy2 = yy[:, [1, 2, 4, 5]]\n",
        "\n",
        "          #import pdb;pdb.set_trace()\n",
        "          y[i, :, :] = yy\n",
        "\n",
        "\n",
        "\n",
        "        # tau = X.shape[1]          \n",
        "        # v = X.shape[2]\n",
        "\n",
        "        # warped_frequency_spectrogram = spec_augment_tensorflow.frequency_masking(X, v=v,  frequency_masking_para=8, frequency_mask_num=1)\n",
        "        # warped_frequency_time_sepctrogram = spec_augment_tensorflow.time_masking(warped_frequency_spectrogram, tau=tau, time_masking_para=25, time_mask_num=3)\n",
        "\n",
        "        # X = warped_frequency_time_sepctrogram\n",
        "\n",
        "        #pdb.set_trace()\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pEd_V_PQAox"
      },
      "source": [
        "# 4. Define Loss function, Binary accuracy and Callback function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRV_V_KGQQDa"
      },
      "source": [
        "## 4.1 Define Loss function and binary accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtnlCGfduBbp"
      },
      "outputs": [],
      "source": [
        "def coherence_loss(y_true, y_pred):\n",
        "  #pdb.set_trace()\n",
        "  # Calculate the squared difference between consecutive predictions\n",
        "  y_pred_shifted = tf.roll(y_pred, shift=-1, axis=1) #z_t-1\n",
        "  coherence_diff = tf.square(y_pred[:, :-1, :] - y_pred_shifted[:, :-1, :]) # [:, :-1, :]\n",
        "  \n",
        "  # we can tune this weight\n",
        "  coherence_weight = 0.1\n",
        "\n",
        "  #alpha1 different max\n",
        "  a1 = -0.1\n",
        "  #alpha2 same min\n",
        "  a2 = 0.03\n",
        "\n",
        "  # Create labels for y_true\n",
        "  #pdb.set_trace()\n",
        "  shape = tf.shape(y_true)\n",
        "  y_true_presentlabel = tf.strided_slice(y_true, [0, 0, 0], [shape[0], shape[1], shape[2]], [1, 1, 3])\n",
        "  y_true_label = tf.tile(y_true_presentlabel,[1,1,3])\n",
        "\n",
        "  #y_true_label = tf.zeros((tf.shape(y_true)[0], tf.shape(y_true)[1], tf.shape(y_true)[2] // 3))\n",
        "  #y_true_label = tf.zeros((32, 32, 10))\n",
        "  #y_true_label = tf.tensor_scatter_nd_update(y_true_label, tf.constant([[0, 0, 0]]), y_true[:, 0, 0:30:3])\n",
        "  #y_true_label = tf.repeat(y_true_label, 3, axis=-1)\n",
        "\n",
        "  # Shift y_true_label\n",
        "  y_true_label_shifted = tf.roll(y_true_label, shift=-1, axis=1)\n",
        "\n",
        "  # Create indices for max and min differences\n",
        "  ind_max = tf.cast(tf.not_equal(y_true_label[:, :-1, :], y_true_label_shifted[:, :-1, :]), tf.float32) # [:, :-1, :]\n",
        "  ind_min = tf.cast(tf.equal(y_true_label[:, :-1, :], y_true_label_shifted[:, :-1, :]), tf.float32) # [:, :-1, :]\n",
        "\n",
        "  # Compute coherence loss\n",
        "  L_coh = a1 * ind_max * coherence_diff + a2 * ind_min * coherence_diff\n",
        "\n",
        "  # Sum the coherence loss along the sequence axis\n",
        "  return coherence_weight * tf.reduce_sum(L_coh, axis=[-1, -2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkw1Rl4RQSJw"
      },
      "outputs": [],
      "source": [
        "def my_loss_fn(y_true, y_pred):\n",
        "  weight = tf.constant([1.0])\n",
        "\n",
        "  squared_difference = tf.square(y_true - y_pred)\n",
        "\n",
        "  # squared_difference[:, 1] =  squared_difference[:, 1] * y_true[:, 0]\n",
        "\n",
        "  # squared_difference[:, 3] =  squared_difference[:, 3] * y_true[:, 2]\n",
        "\n",
        "  ss_True = squared_difference[:, :, 0] * 0 + 1\n",
        "\n",
        "  ss_0 = y_true[:, :, 0]\n",
        "  ss_1 = y_true[:, :, 3]\n",
        "  ss_2 = y_true[:, :, 6]\n",
        "  ss_3 = y_true[:, :, 9]\n",
        "  ss_4 = y_true[:, :, 12]\n",
        "  ss_5 = y_true[:, :, 15]\n",
        "  ss_6 = y_true[:, :, 18]\n",
        "  ss_7 = y_true[:, :, 21]\n",
        "  ss_8 = y_true[:, :, 24]\n",
        "  ss_9 = y_true[:, :, 27]\n",
        "\n",
        "  sss = tf.stack((ss_True, ss_0, ss_0,\n",
        "                  ss_True, ss_1, ss_1,\n",
        "                  ss_True, ss_2, ss_2,\n",
        "                  ss_True, ss_3, ss_3,\n",
        "                  ss_True, ss_4, ss_4,\n",
        "                  ss_True, ss_5, ss_5,\n",
        "                  ss_True, ss_5, ss_6,\n",
        "                  ss_True, ss_5, ss_7,\n",
        "                  ss_True, ss_5, ss_8,\n",
        "                  ss_True, ss_5, ss_9), axis = 2)\n",
        "  \n",
        "  squared_difference =  tf.multiply(squared_difference, sss)\n",
        "\n",
        "  # mask_1 = tf.cast(tf.equal(ss1, 0), dtype = np.float32)\n",
        "  # mask_1 = mask_1 * weight\n",
        "\n",
        "  # mask_2 = tf.cast(tf.equal(ss1, 1), dtype = np.float32)\n",
        "\n",
        "  # mask_3 = tf.cast(tf.equal(ss4, 0), dtype = np.float32)\n",
        "  # mask_3 = mask_3 * weight\n",
        "\n",
        "  # mask_4 = tf.cast(tf.equal(ss4, 1), dtype = np.float32)\n",
        "\n",
        "  # mask_s = mask_1 + mask_2\n",
        "\n",
        "  # mask_m = mask_3 + mask_4\n",
        "\n",
        "  # mmm = tf.stack((mask_s, ss0, ss0, mask_m, ss3, ss3), axis = 2)\n",
        "\n",
        "  # squared_difference =  tf.multiply(squared_difference, mmm)\n",
        "\n",
        "  # Add coherence loss to your existing loss\n",
        "  total_loss = tf.reduce_sum(squared_difference, axis=[-1, -2]) + coherence_loss(y_true, y_pred)\n",
        "\n",
        "  return total_loss #tf.reduce_sum(squared_difference, axis=[-1, -2])  # Note the `axis=-1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTUszNYxQUtF"
      },
      "outputs": [],
      "source": [
        "def binary_acc(y_true, y_pred):\n",
        "  threshold = tf.constant([0.5])\n",
        "\n",
        "  binary_true = tf.stack((y_true[:, :, 0], y_true[:, :, 3], y_true[:, :, 6], y_true[:, :, 9], y_true[:, :, 12],\n",
        "                          y_true[:, :, 15], y_true[:, :, 18], y_true[:, :, 21], y_true[:, :, 24], y_true[:, :, 27]), axis=1)\n",
        "  binary_pred = tf.stack((y_pred[:, :, 0], y_pred[:, :, 3], y_pred[:, :, 6], y_pred[:, :, 9], y_pred[:, :, 12]\n",
        "                          , y_pred[:, :, 15], y_pred[:, :, 18], y_pred[:, :, 21], y_pred[:, :, 24], y_pred[:, :, 27]), axis=1)\n",
        "\n",
        "  binary_true = tf.greater_equal(binary_true, threshold)\n",
        "  binary_pred = tf.greater_equal(binary_pred, threshold)\n",
        "\n",
        "  # binary_pred = tf.greater(y_pred[:, [0, 2]], threshold)\n",
        "\n",
        "  # acc = tf.square(y_true - y_pred)\n",
        "  acc = tf.cast((binary_true == binary_pred), tf.float32)\n",
        "\n",
        "  return tf.reduce_mean(acc, axis=[-1, -2])  # Note the `axis=-1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYxzEvNBQXcv"
      },
      "source": [
        "## 4.2 Callback functions\n",
        "\n",
        "callback is a set of functions that are applied at various stages of the training process. Callbacks can be used to perform a wide range of tasks during training, such as:\n",
        "\n",
        "- Saving the model or model weights at specified intervals.\n",
        "- Stopping the training process early based on a specific metric or condition.\n",
        "- Adjusting the learning rate of the optimizer during training.\n",
        "- Logging metrics or other information during training.\n",
        "\n",
        "Customized Callback Included in this block:\n",
        "\n",
        "- MyCustomCallback_3: report only loss\n",
        "- MyCustomCallback_44: report loss, f-measure loss, error rate\n",
        "  - Need mk_preds_YOHO_mel_2\n",
        "  - save to \"/content/eval-files-2/\"\n",
        "- MyCustomCallback_CRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E-si5qWQdmL"
      },
      "outputs": [],
      "source": [
        "# This optimises val loss for Wave-U-Net YOHO\n",
        "# Back to Val Binary acc.\n",
        "class MyCustomCallback_3(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, model_dir, patience=0):\n",
        "    super(MyCustomCallback_3, self).__init__()\n",
        "    self.patience = patience\n",
        "    # best_weights to store the weights at which the minimum loss occurs.\n",
        "    self.best_weights = None\n",
        "    self.model_best_path = os.path.join(model_dir, 'model-best.h5')\n",
        "    self.model_last_path = os.path.join(model_dir, 'model-last-epoch.h5')\n",
        "    self.custom_params = {\"best_loss\":np.inf, \"last_epoch\":0}\n",
        "    \n",
        "    self.custom_params_path = os.path.join(model_dir, 'custom_params.pickle')\n",
        "    if os.path.isfile(self.custom_params_path):\n",
        "      with open(self.custom_params_path, 'rb') as f:\n",
        "        self.custom_params = pickle.load(f)\n",
        "      # best_model = tf.keras.models.load_model(self.model_best_path, custom_objects={'my_loss_fn':my_loss_fn, \n",
        "      #             'binary_acc':binary_acc, 'TCN':TCN(), 'SpeechF1':SpeechF1(), 'MusicF1':MusicF1(),\n",
        "      #             'OnAcc':OnAcc(), 'OnOffAcc':OnOffAcc(),'AudioClipLayer':AudioClipLayer(), \n",
        "      #             'InterpolationLayer':InterpolationLayer(), 'CropLayer':CropLayer(),\n",
        "      #             'IndependentOutputLayer':IndependentOutputLayer(), 'DiffOutputLayer':DiffOutputLayer()})\n",
        "      # best_model = tf.keras.models.clone_model(self.model)\n",
        "      # best_model.load_weights(self.model_best_path)\n",
        "      # self.best_weights = best_model.get_weights()\n",
        "\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    # The number of epoch it has waited when loss is no longer minimum.\n",
        "    self.wait = 0\n",
        "    # The epoch the training stops at.\n",
        "    self.stopped_epoch = 0\n",
        "    # Initialize the best F1 as 0.0.\n",
        "    self.is_impatient = False\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if not self.is_impatient:\n",
        "      print(\"Restoring model weights from the end of the best epoch.\")\n",
        "      self.model.set_weights(self.best_weights)\n",
        "      # temp_model_path = self.model_path.replace(\".h5\", \"_temp.h5\")\n",
        "      #os.remove(temp_model_path)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current_val_loss = logs.get(\"val_loss\")\n",
        "    self.model.save_weights(self.model_last_path)\n",
        "    self.custom_params[\"last_epoch\"] = self.custom_params[\"last_epoch\"] + 1\n",
        "\n",
        "    if current_val_loss < self.custom_params['best_loss']:\n",
        "      self.custom_params['best_loss'] = current_val_loss\n",
        "      self.wait = 0\n",
        "      self.best_weights = self.model.get_weights()\n",
        "      self.model.save_weights(self.model_best_path)\n",
        "\n",
        "    else:\n",
        "        self.wait += 1\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.is_impatient = True\n",
        "            self.model.stop_training = True\n",
        "            print(\"Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)\n",
        "            #os.remove(temp_model_path)\n",
        "    with open(self.custom_params_path, 'wb') as f:\n",
        "      pickle.dump(self.custom_params, f, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOmb5k1zQo_L"
      },
      "outputs": [],
      "source": [
        "class MyCustomCallback_44(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super(MyCustomCallback_44, self).__init__()\n",
        "    self.best_f1 = 0.0\n",
        "    self.best_error = np.inf\n",
        "\n",
        "    \n",
        "  def on_train_begin(self, logs=None):\n",
        "    pass\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    pass\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if True:\n",
        "      start_time = time.time()\n",
        "\n",
        "      # for ii, audio in enumerate(val_files):\n",
        "      #   audio_file_path = audio\n",
        "      #   see = mk_preds_YOHO_mel(self.model, ii)\n",
        "      #   n_label = n_label = \"/content/eval-files-2/\" + os.path.basename(audio_file_path).replace(\".wav\" ,\"\") + \"-se-prediction.txt\"\n",
        "\n",
        "      #   with open(n_label, 'w') as fp:\n",
        "      #     fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))\n",
        "\n",
        "      mk_preds_YOHO_mel_2(self.model, mss_ins=mss_ins_2)\n",
        "\n",
        "      stop_time = time.time()\n",
        "      # print(\"Time for prediction: {}\".format(stop_time - start_time))\n",
        "\n",
        "      start_time = time.time()\n",
        "      destination = \"/content/eval-files-2/\"\n",
        "      test_set = glob.glob(destination + \"*[0-9].txt\")\n",
        "\n",
        "      eval_path = \"/content/\"\n",
        "\n",
        "\n",
        "      file_list = [\n",
        "          {\n",
        "          'reference_file': tt,\n",
        "          'estimated_file': tt.replace(\".txt\",\"-se-prediction.txt\")\n",
        "          }\n",
        "          for tt in test_set\n",
        "      ]\n",
        "\n",
        "      data = []\n",
        "\n",
        "      # Get used event labels\n",
        "      all_data = dcase_util.containers.MetaDataContainer()\n",
        "      for file_pair in file_list:\n",
        "          reference_event_list = sed_eval.io.load_event_list(\n",
        "              filename=file_pair['reference_file']\n",
        "          )\n",
        "          estimated_event_list = sed_eval.io.load_event_list(\n",
        "              filename=file_pair['estimated_file']\n",
        "          )\n",
        "\n",
        "          data.append({'reference_event_list': reference_event_list,\n",
        "                      'estimated_event_list': estimated_event_list})\n",
        "\n",
        "          all_data += reference_event_list\n",
        "\n",
        "      event_labels = all_data.unique_event_labels\n",
        "\n",
        "      # Start evaluating\n",
        "      # Create metrics classes, define parameters\n",
        "      segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\n",
        "          event_label_list=event_labels,\n",
        "          time_resolution=1.0\n",
        "      )\n",
        "\n",
        "      event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\n",
        "          event_label_list=event_labels,\n",
        "          t_collar=1.0\n",
        "      )\n",
        "\n",
        "      # Go through files\n",
        "      for file_pair in data:\n",
        "          segment_based_metrics.evaluate(\n",
        "              reference_event_list=file_pair['reference_event_list'],\n",
        "              estimated_event_list=file_pair['estimated_event_list']\n",
        "          )\n",
        "\n",
        "          event_based_metrics.evaluate(\n",
        "              reference_event_list=file_pair['reference_event_list'],\n",
        "              estimated_event_list=file_pair['estimated_event_list']\n",
        "          )\n",
        "\n",
        "      # Get only certain metrics\n",
        "      overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\n",
        "      curr_f1 = overall_segment_based_metrics['f_measure']['f_measure']\n",
        "      curr_error = overall_segment_based_metrics['error_rate']['error_rate']\n",
        "\n",
        "      if curr_f1 > self.best_f1:\n",
        "        self.best_f1 = curr_f1\n",
        "        self.model.save_weights(\"/content/drive/MyDrive/model-best-f1.h5\")\n",
        "\n",
        "      if curr_error < self.best_error:\n",
        "        self.best_error = curr_error\n",
        "        self.model.save_weights(\"/content/drive/MyDrive/model-best-error.h5\")\n",
        "\n",
        "      print(\"F-measure: {:.3f} vs {:.3f}\".format(curr_f1, self.best_f1))\n",
        "      print(\"Error rate: {:.3f} vs {:.3f}\".format(curr_error, self.best_error))\n",
        "\n",
        "      stop_time = time.time()\n",
        "\n",
        "      # print(\"Time to calculate metrics: {}\".format(stop_time - start_time))\n",
        "\n",
        "      # Or print all metrics as reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhO6NxuMQxKS"
      },
      "source": [
        "## 4.3 Callback44 helper function: mk_preds_YOHO_mel_2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjojcnQmR-2P"
      },
      "source": [
        "### Initialize mss_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWR03dJRBdH",
        "outputId": "f4d7298c-993c-47eb-b1f7-8f16a89dcfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n",
            "[0, 441000]\n",
            "[0]\n",
            "[0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2000, 1001, 40)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rev class dict\n",
        "rev_class_dict = ['air_conditioner', 'car_horn', 'children_playing',\n",
        "          'dog_bark', 'drilling', 'engine_idling', 'gun_shot',\n",
        "          'jackhammer','siren', 'street_music']\n",
        "\n",
        "# Creates mel spctrograms for training\n",
        "\n",
        "win_length = 10.0\n",
        "hop_size = 10.0\n",
        "mss_ins = []\n",
        "win_ranges_list = []\n",
        "n_classes = 10\n",
        "\n",
        "for ii, audio in enumerate(val_files):\n",
        "  a, win_ranges = construct_examples(audio, win_len=win_length,hop_len=hop_size)\n",
        "\n",
        "  mss_in = np.zeros((1, 1001, 40))\n",
        "\n",
        "  # if len(a) > 1:\n",
        "  #   print(audio)\n",
        "\n",
        "  preds = np.zeros((len(a), 3, 30)) # I think this is an unused variable\n",
        "\n",
        "\n",
        "  for i in range(1):\n",
        "    M = get_log_melspectrogram(a[i])\n",
        "    mss_in[i, :, :] = M.T\n",
        "  mss_ins.append(mss_in)\n",
        "  win_ranges_list.append(win_ranges)\n",
        "\n",
        "#test\n",
        "a, sr = sf.read(\"/content/Urban-SED/URBAN-SED_v2.0.0/audio/validate/soundscape_validate_bimodal528.wav\")\n",
        "a.shape[0]/sr\n",
        "len(mss_ins) #2000\n",
        "mss_ins_2 = np.concatenate(mss_ins, axis=0)\n",
        "mss_ins_2.shape #2000,1001,40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrO5mjAnRoVB"
      },
      "outputs": [],
      "source": [
        "def extract_labels_2(annotation_path):\n",
        "  events = read_annotation(annotation_path)\n",
        "\n",
        "  ann = [[float(e[0]), float(e[1]), e[2]] for e in events]\n",
        "  \n",
        "  n_label = \"/content/eval-files-2/\" + os.path.basename(annotation_path)\n",
        "\n",
        "  with open(n_label, 'w') as fp:\n",
        "    fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in ann))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYgzLWUDRrvv"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/content/eval-files-2/\"):\n",
        "  os.mkdir(\"/content/eval-files-2/\")\n",
        "for audio in val_files:\n",
        "  extract_labels_2(audio.replace(\".wav\", \".txt\").replace(\"audio\", \"annotations\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQLlRL80RzDC"
      },
      "source": [
        "### Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_T8LkUQRGZ1"
      },
      "outputs": [],
      "source": [
        "def mk_preds_YOHO_mel_2(model, mss_ins=mss_ins_2, no_of_div = 32, hop_size = 10.0, discard = 0.3, win_length = 10.0, max_event_silence = 0.3, sampling_rate = 44100):\n",
        "  preds = model.predict(mss_ins_2)\n",
        "\n",
        "  for ii, audio in enumerate(val_files):\n",
        "    audio_file_path = audio\n",
        "\n",
        "    events = []\n",
        "    p = preds[ii, :, :]\n",
        "    events_curr = []\n",
        "    win_width = win_length / no_of_div\n",
        "    for j in range(len(p)):\n",
        "      for jjj in range(0, n_classes):\n",
        "        if p[j][jjj*3] >= 0.5:\n",
        "          start = win_width * j + win_width * p[j][jjj*3+1] + win_ranges_list[ii][0][0]\n",
        "          end = p[j][jjj*3+2] * win_width + start\n",
        "          events_curr.append([start, end, rev_class_dict[jjj]])\n",
        "\n",
        "    events += events_curr\n",
        "\n",
        "\n",
        "    class_set = set([c[2] for c in events])\n",
        "    class_wise_events = {}\n",
        "\n",
        "    for c in list(class_set):\n",
        "      class_wise_events[c] = []\n",
        "\n",
        "\n",
        "    for c in events:\n",
        "      class_wise_events[c[2]].append(c)\n",
        "      \n",
        "    \n",
        "    all_events = []\n",
        "\n",
        "    for k in list(class_wise_events.keys()):\n",
        "      curr_events = class_wise_events[k]\n",
        "      count = 0\n",
        "\n",
        "      while count < len(curr_events) - 1:\n",
        "        if (curr_events[count][1] >= curr_events[count + 1][0]) or (curr_events[count + 1][0] - curr_events[count][1] <= max_event_silence):\n",
        "          curr_events[count][1] = max(curr_events[count + 1][1], curr_events[count][1])\n",
        "          del curr_events[count + 1]\n",
        "        else:\n",
        "          count += 1\n",
        "\n",
        "      all_events += curr_events\n",
        "\n",
        "    for i in range(len(all_events)):\n",
        "      all_events[i][0] = round(all_events[i][0], 3)\n",
        "      all_events[i][1] = round(all_events[i][1], 3)\n",
        "\n",
        "    all_events.sort(key=lambda x: x[0])\n",
        "\n",
        "\n",
        "\n",
        "    see = all_events\n",
        "    n_label = n_label = \"/content/eval-files-2/\" + os.path.basename(audio_file_path).replace(\".wav\" ,\"\") + \"-se-prediction.txt\"\n",
        "\n",
        "    with open(n_label, 'w') as fp:\n",
        "      fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KIGYC0jRY4D"
      },
      "outputs": [],
      "source": [
        "def frames_to_time(f, sr = 44100.0, hop_size = 441):\n",
        "  return f * hop_size / sr\n",
        "\n",
        "def preds_to_se(p, win_start, audio_clip_length = 2.56):\n",
        "  start_dicts = [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
        "  stop_dicts = [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
        "\n",
        "\n",
        "  start_speech = -100\n",
        "  start_music = -100\n",
        "  stop_speech = -100\n",
        "  stop_music = -100\n",
        "\n",
        "  audio_events = []\n",
        "\n",
        "  n_frames = p.shape[0]\n",
        "\n",
        "  for j in range(p.shape[1]):\n",
        "    if p[0, j] >= 0.5:\n",
        "      start_dicts[j] = 0\n",
        "\n",
        "  for j in range(p.shape[1]):\n",
        "    for i in range(n_frames - 1):\n",
        "      if p[i, j] < 0.5 and p[i+1, j] >= 0.5:\n",
        "        start_dicts[j] = i+1\n",
        "\n",
        "      elif p[i, j] >= 0.5 and p[i + 1, j] < 0.5:\n",
        "        stop_dicts[j] = i\n",
        "        start_time = frames_to_time(start_dicts[j])\n",
        "        stop_time = frames_to_time(stop_dicts[j])\n",
        "\n",
        "        audio_events.append([start_time+win_start, stop_time+win_start, rev_class_dict[j]])\n",
        "        start_dicts[j] = -100\n",
        "        stop_dicts[j] = -100\n",
        "\n",
        "    if start_dicts[j] != -100:\n",
        "      start_time = frames_to_time(start_dicts[j])\n",
        "      stop_time = audio_clip_length\n",
        "      audio_events.append([start_time+win_start, stop_time+win_start, rev_class_dict[j]])\n",
        "      start_dicts[j] = -100\n",
        "      stop_dicts[j] = -100\n",
        "\n",
        "  audio_events.sort(key = lambda x: x[0]) \n",
        "  return audio_events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLdShZpASJ8w"
      },
      "source": [
        "# 5. Define the YamNet Model\n",
        "- YOHO adapted from MobileNet, modified the final layers\n",
        "- MobileNet has also been employed for audio classification by  YamNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMo68_RlSRs6"
      },
      "outputs": [],
      "source": [
        "LAYER_DEFS = [\n",
        "    # (layer_function, kernel, stride, num_filters)\n",
        "    ([3, 3], 1,   64),\n",
        "    ([3, 3], 2,  128),\n",
        "    ([3, 3], 1,  128),\n",
        "    ([3, 3], 2,  256),\n",
        "    ([3, 3], 1,  256),\n",
        "    ([3, 3], 2,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 2, 1024),\n",
        "    ([3, 3], 1, 1024),\n",
        "    ([3, 3], 1, 512),\n",
        "    ([3, 3], 1, 256),\n",
        "    ([3, 3], 1, 128),\n",
        "    # ([3, 3], 1, 128),\n",
        "    # ([3, 3], 1, 128)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSzXq59BSViw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Manually define YamNet\n",
        "\"\"\"\n",
        "\n",
        "rbm_layer1_shape = 1001\n",
        "rbm_layer2_1_shape = 700\n",
        "rbm_layer2_2_shape = 301\n",
        "\n",
        "# params = yamnet_params.Params()\n",
        "m_features = tf.keras.Input(shape=(1001, 40), name=\"mel_input\")\n",
        "\n",
        "X = tf.keras.layers.Reshape((1001, 40))(m_features)  \n",
        "\n",
        "#X = m_features\n",
        "\n",
        "# add linear layer and relu for RBM layer 1, output X is hidden_activation, shape (1001,)\n",
        "X = tf.keras.layers.Reshape(target_shape=(-1, 1001 * 40))(X)\n",
        "rbm_feature_1 = tf.keras.layers.Dense(units=rbm_layer1_shape, activation='sigmoid',name='rbm_1')(X) #reshape((-1, 1001 * 40))\n",
        "\n",
        "# add linear layer and relu for RBM layer 2 \n",
        "X1 = tf.keras.layers.Dense(units=rbm_layer2_1_shape, activation='sigmoid',name='rbm_2_1')(rbm_feature_1)\n",
        "X2 = tf.keras.layers.Dense(units=rbm_layer2_2_shape, activation='sigmoid',name='rbm_2_2')(rbm_feature_1)\n",
        "\n",
        "#X1 = tf.keras.layers.Reshape(target_shape=(rbm_layer2_1_shape,1))(X1)\n",
        "#X2 = tf.keras.layers.Reshape(target_shape=(rbm_layer2_2_shape,1))(X2)\n",
        "rbm_feature_2 = tf.concat([X1,X2],axis=2)  \n",
        "\n",
        "# combine spectrogram and hidden feature, resulting in (1001, 40+n) \n",
        "#rbm_feature_1 = tf.expand_dims(rbm_feature_1, axis=-1) \n",
        "#bm_feature_2 = tf.expand_dims(rbm_feature_2, axis=-1) \n",
        "\n",
        "#rbm_feature_1 = tf.keras.layers.Reshape(target_shape=(1001,1))(rbm_feature_1)\n",
        "#rbm_feature_2 = tf.keras.layers.Reshape(target_shape=(1001,1))(rbm_feature_2)\n",
        "rbm_feature_1 = tf.transpose(rbm_feature_1, perm=[0, 2, 1])\n",
        "rbm_feature_2 = tf.transpose(rbm_feature_2, perm=[0, 2, 1])\n",
        "\n",
        "concat_feature = tf.concat([m_features,rbm_feature_1,rbm_feature_2],axis=2)  # tf has place holder for batch_size at axis=0\n",
        "\n",
        "# original CNN network starting from here \n",
        "\n",
        "X = tf.keras.layers.Reshape((1001, 42, 1))(concat_feature)  \n",
        "X = tf.keras.layers.Conv2D(filters = 32, kernel_size=[3, 3], strides=2, padding='same', use_bias=False,\n",
        "                           activation=None, name = \"layer1/conv\",\n",
        "                             kernel_regularizer=l2(1e-3), bias_regularizer=l2(1e-3))(X)\n",
        "X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer1/bn\")(X)\n",
        "X = tf.keras.layers.ReLU(name=\"layer1/relu\")(X)\n",
        "\n",
        "# X = tf.keras.layers.SpatialDropout2D(0.5)(X)  \n",
        "\n",
        "for i in range(len(LAYER_DEFS)):\n",
        "  X = tf.keras.layers.DepthwiseConv2D(kernel_size=LAYER_DEFS[i][0], strides = LAYER_DEFS[i][1], depth_multiplier=1, padding='same', use_bias=False,\n",
        "                                      activation=None, name=\"layer\"+ str(i + 2)+\"/depthwise_conv\")(X)\n",
        "  X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(i + 2)+\"/depthwise_conv/bn\")(X)\n",
        "  X = tf.keras.layers.ReLU(name=\"layer\"+ str(i + 2)+\"/depthwise_conv/relu\")(X)\n",
        "  X = tf.keras.layers.Conv2D(filters = LAYER_DEFS[i][2], kernel_size=[1, 1], strides=1, padding='same', use_bias=False, activation=None,\n",
        "                             name = \"layer\"+ str(i + 2)+\"/pointwise_conv\",\n",
        "                             kernel_regularizer=l2(1e-2), bias_regularizer=l2(1e-2))(X)\n",
        "  X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(i + 2)+\"/pointwise_conv/bn\")(X)\n",
        "  X = tf.keras.layers.ReLU(name=\"layer\"+ str(i + 2)+\"/pointwise_conv/relu\")(X)\n",
        "\n",
        "  X = tf.keras.layers.SpatialDropout2D(0.1)(X)\n",
        "\n",
        "  # X = tf.keras.layers.Dropout(0.1)(X)\n",
        "\n",
        "\n",
        "# X = tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides = 1, depth_multiplier=1, padding='same', use_bias=False, activation=None, name=\"layer2/depthwise_conv\")(X)\n",
        "# X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer2/depthwise_conv/bn\")(X)\n",
        "# X = tf.keras.layers.ReLU(name=\"layer2/depthwise_conv/relu\")(X)\n",
        "# X = tf.keras.layers.Conv2D(filters = 64, kernel_size=[1, 1], strides=1, padding='same', use_bias=False, activation=None, name = \"layer2/pointwise_conv\")(X)\n",
        "# X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer2/pointwise_conv/bn\")(X)\n",
        "# X = tf.keras.layers.ReLU(name=\"layer2/pointwise_conv/relu\")(X)\n",
        "\n",
        "_, _, sx, sy = X.shape\n",
        "X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\n",
        "# X = tf.keras.layers.Dropout(0.4)(X)\n",
        "\n",
        "# X = _separable_conv(\"extra\", [3, 3], 2, 1024, params)(predictions)\n",
        "# X = tf.keras.layers.Lambda(lambda x: tf.squeeze(x, axis=-2))(X)\n",
        "# X = layers.Dense(2, name=\"speech_and_music\", activation='sigmoid')(embeddings)\n",
        "# X = tf.keras.layers.Flatten()(X)\n",
        "pred = tf.keras.layers.Conv1D(30,kernel_size=1, activation=\"sigmoid\")(X)\n",
        "# pred = tf.keras.layers.Dense(6, activation=\"sigmoid\")(X)\n",
        "model = tf.keras.Model(\n",
        "      name='yamnet_frames', inputs=m_features,\n",
        "      outputs=[pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Y28sGrSYxi",
        "outputId": "40f6862d-7a8e-4388-ec76-ad64584fcd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"yamnet_frames\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " mel_input (InputLayer)         [(None, 1001, 40)]   0           []                               \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1001, 40)     0           ['mel_input[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 40040)     0           ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " rbm_1 (Dense)                  (None, 1, 1001)      40081041    ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " rbm_2_1 (Dense)                (None, 1, 700)       701400      ['rbm_1[0][0]']                  \n",
            "                                                                                                  \n",
            " rbm_2_2 (Dense)                (None, 1, 301)       301602      ['rbm_1[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 1, 1001)      0           ['rbm_2_1[0][0]',                \n",
            "                                                                  'rbm_2_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TFOpLa  (None, 1001, 1)     0           ['rbm_1[0][0]']                  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_1 (TFOp  (None, 1001, 1)     0           ['tf.concat[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, 1001, 42)     0           ['mel_input[0][0]',              \n",
            "                                                                  'tf.compat.v1.transpose[0][0]', \n",
            "                                                                  'tf.compat.v1.transpose_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1001, 42, 1)  0           ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " layer1/conv (Conv2D)           (None, 501, 21, 32)  288         ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " layer1/bn (BatchNormalization)  (None, 501, 21, 32)  96         ['layer1/conv[0][0]']            \n",
            "                                                                                                  \n",
            " layer1/relu (ReLU)             (None, 501, 21, 32)  0           ['layer1/bn[0][0]']              \n",
            "                                                                                                  \n",
            " layer2/depthwise_conv (Depthwi  (None, 501, 21, 32)  288        ['layer1/relu[0][0]']            \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer2/depthwise_conv/bn (Batc  (None, 501, 21, 32)  96         ['layer2/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer2/depthwise_conv/relu (Re  (None, 501, 21, 32)  0          ['layer2/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer2/pointwise_conv (Conv2D)  (None, 501, 21, 64)  2048       ['layer2/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer2/pointwise_conv/bn (Batc  (None, 501, 21, 64)  192        ['layer2/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer2/pointwise_conv/relu (Re  (None, 501, 21, 64)  0          ['layer2/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d (SpatialDrop  (None, 501, 21, 64)  0          ['layer2/pointwise_conv/relu[0][0\n",
            " out2D)                                                          ]']                              \n",
            "                                                                                                  \n",
            " layer3/depthwise_conv (Depthwi  (None, 251, 11, 64)  576        ['spatial_dropout2d[0][0]']      \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer3/depthwise_conv/bn (Batc  (None, 251, 11, 64)  192        ['layer3/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer3/depthwise_conv/relu (Re  (None, 251, 11, 64)  0          ['layer3/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer3/pointwise_conv (Conv2D)  (None, 251, 11, 128  8192       ['layer3/depthwise_conv/relu[0][0\n",
            "                                )                                ]']                              \n",
            "                                                                                                  \n",
            " layer3/pointwise_conv/bn (Batc  (None, 251, 11, 128  384        ['layer3/pointwise_conv[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " layer3/pointwise_conv/relu (Re  (None, 251, 11, 128  0          ['layer3/pointwise_conv/bn[0][0]'\n",
            " LU)                            )                                ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_1 (SpatialDr  (None, 251, 11, 128  0          ['layer3/pointwise_conv/relu[0][0\n",
            " opout2D)                       )                                ]']                              \n",
            "                                                                                                  \n",
            " layer4/depthwise_conv (Depthwi  (None, 251, 11, 128  1152       ['spatial_dropout2d_1[0][0]']    \n",
            " seConv2D)                      )                                                                 \n",
            "                                                                                                  \n",
            " layer4/depthwise_conv/bn (Batc  (None, 251, 11, 128  384        ['layer4/depthwise_conv[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " layer4/depthwise_conv/relu (Re  (None, 251, 11, 128  0          ['layer4/depthwise_conv/bn[0][0]'\n",
            " LU)                            )                                ]                                \n",
            "                                                                                                  \n",
            " layer4/pointwise_conv (Conv2D)  (None, 251, 11, 128  16384      ['layer4/depthwise_conv/relu[0][0\n",
            "                                )                                ]']                              \n",
            "                                                                                                  \n",
            " layer4/pointwise_conv/bn (Batc  (None, 251, 11, 128  384        ['layer4/pointwise_conv[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " layer4/pointwise_conv/relu (Re  (None, 251, 11, 128  0          ['layer4/pointwise_conv/bn[0][0]'\n",
            " LU)                            )                                ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_2 (SpatialDr  (None, 251, 11, 128  0          ['layer4/pointwise_conv/relu[0][0\n",
            " opout2D)                       )                                ]']                              \n",
            "                                                                                                  \n",
            " layer5/depthwise_conv (Depthwi  (None, 126, 6, 128)  1152       ['spatial_dropout2d_2[0][0]']    \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer5/depthwise_conv/bn (Batc  (None, 126, 6, 128)  384        ['layer5/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer5/depthwise_conv/relu (Re  (None, 126, 6, 128)  0          ['layer5/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer5/pointwise_conv (Conv2D)  (None, 126, 6, 256)  32768      ['layer5/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer5/pointwise_conv/bn (Batc  (None, 126, 6, 256)  768        ['layer5/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer5/pointwise_conv/relu (Re  (None, 126, 6, 256)  0          ['layer5/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_3 (SpatialDr  (None, 126, 6, 256)  0          ['layer5/pointwise_conv/relu[0][0\n",
            " opout2D)                                                        ]']                              \n",
            "                                                                                                  \n",
            " layer6/depthwise_conv (Depthwi  (None, 126, 6, 256)  2304       ['spatial_dropout2d_3[0][0]']    \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer6/depthwise_conv/bn (Batc  (None, 126, 6, 256)  768        ['layer6/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer6/depthwise_conv/relu (Re  (None, 126, 6, 256)  0          ['layer6/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer6/pointwise_conv (Conv2D)  (None, 126, 6, 256)  65536      ['layer6/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer6/pointwise_conv/bn (Batc  (None, 126, 6, 256)  768        ['layer6/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer6/pointwise_conv/relu (Re  (None, 126, 6, 256)  0          ['layer6/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_4 (SpatialDr  (None, 126, 6, 256)  0          ['layer6/pointwise_conv/relu[0][0\n",
            " opout2D)                                                        ]']                              \n",
            "                                                                                                  \n",
            " layer7/depthwise_conv (Depthwi  (None, 63, 3, 256)  2304        ['spatial_dropout2d_4[0][0]']    \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer7/depthwise_conv/bn (Batc  (None, 63, 3, 256)  768         ['layer7/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer7/depthwise_conv/relu (Re  (None, 63, 3, 256)  0           ['layer7/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer7/pointwise_conv (Conv2D)  (None, 63, 3, 512)  131072      ['layer7/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer7/pointwise_conv/bn (Batc  (None, 63, 3, 512)  1536        ['layer7/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer7/pointwise_conv/relu (Re  (None, 63, 3, 512)  0           ['layer7/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_5 (SpatialDr  (None, 63, 3, 512)  0           ['layer7/pointwise_conv/relu[0][0\n",
            " opout2D)                                                        ]']                              \n",
            "                                                                                                  \n",
            " layer8/depthwise_conv (Depthwi  (None, 63, 3, 512)  4608        ['spatial_dropout2d_5[0][0]']    \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer8/depthwise_conv/bn (Batc  (None, 63, 3, 512)  1536        ['layer8/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer8/depthwise_conv/relu (Re  (None, 63, 3, 512)  0           ['layer8/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer8/pointwise_conv (Conv2D)  (None, 63, 3, 512)  262144      ['layer8/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer8/pointwise_conv/bn (Batc  (None, 63, 3, 512)  1536        ['layer8/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer8/pointwise_conv/relu (Re  (None, 63, 3, 512)  0           ['layer8/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_6 (SpatialDr  (None, 63, 3, 512)  0           ['layer8/pointwise_conv/relu[0][0\n",
            " opout2D)                                                        ]']                              \n",
            "                                                                                                  \n",
            " layer9/depthwise_conv (Depthwi  (None, 63, 3, 512)  4608        ['spatial_dropout2d_6[0][0]']    \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " layer9/depthwise_conv/bn (Batc  (None, 63, 3, 512)  1536        ['layer9/depthwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer9/depthwise_conv/relu (Re  (None, 63, 3, 512)  0           ['layer9/depthwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " layer9/pointwise_conv (Conv2D)  (None, 63, 3, 512)  262144      ['layer9/depthwise_conv/relu[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " layer9/pointwise_conv/bn (Batc  (None, 63, 3, 512)  1536        ['layer9/pointwise_conv[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " layer9/pointwise_conv/relu (Re  (None, 63, 3, 512)  0           ['layer9/pointwise_conv/bn[0][0]'\n",
            " LU)                                                             ]                                \n",
            "                                                                                                  \n",
            " spatial_dropout2d_7 (SpatialDr  (None, 63, 3, 512)  0           ['layer9/pointwise_conv/relu[0][0\n",
            " opout2D)                                                        ]']                              \n",
            "                                                                                                  \n",
            " layer10/depthwise_conv (Depthw  (None, 63, 3, 512)  4608        ['spatial_dropout2d_7[0][0]']    \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer10/depthwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer10/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer10/depthwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer10/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer10/pointwise_conv (Conv2D  (None, 63, 3, 512)  262144      ['layer10/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer10/pointwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer10/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer10/pointwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer10/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_8 (SpatialDr  (None, 63, 3, 512)  0           ['layer10/pointwise_conv/relu[0][\n",
            " opout2D)                                                        0]']                             \n",
            "                                                                                                  \n",
            " layer11/depthwise_conv (Depthw  (None, 63, 3, 512)  4608        ['spatial_dropout2d_8[0][0]']    \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer11/depthwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer11/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer11/depthwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer11/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer11/pointwise_conv (Conv2D  (None, 63, 3, 512)  262144      ['layer11/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer11/pointwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer11/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer11/pointwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer11/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_9 (SpatialDr  (None, 63, 3, 512)  0           ['layer11/pointwise_conv/relu[0][\n",
            " opout2D)                                                        0]']                             \n",
            "                                                                                                  \n",
            " layer12/depthwise_conv (Depthw  (None, 63, 3, 512)  4608        ['spatial_dropout2d_9[0][0]']    \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer12/depthwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer12/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer12/depthwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer12/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer12/pointwise_conv (Conv2D  (None, 63, 3, 512)  262144      ['layer12/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer12/pointwise_conv/bn (Bat  (None, 63, 3, 512)  1536        ['layer12/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer12/pointwise_conv/relu (R  (None, 63, 3, 512)  0           ['layer12/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_10 (SpatialD  (None, 63, 3, 512)  0           ['layer12/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " layer13/depthwise_conv (Depthw  (None, 32, 2, 512)  4608        ['spatial_dropout2d_10[0][0]']   \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer13/depthwise_conv/bn (Bat  (None, 32, 2, 512)  1536        ['layer13/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer13/depthwise_conv/relu (R  (None, 32, 2, 512)  0           ['layer13/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer13/pointwise_conv (Conv2D  (None, 32, 2, 1024)  524288     ['layer13/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer13/pointwise_conv/bn (Bat  (None, 32, 2, 1024)  3072       ['layer13/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer13/pointwise_conv/relu (R  (None, 32, 2, 1024)  0          ['layer13/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_11 (SpatialD  (None, 32, 2, 1024)  0          ['layer13/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " layer14/depthwise_conv (Depthw  (None, 32, 2, 1024)  9216       ['spatial_dropout2d_11[0][0]']   \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer14/depthwise_conv/bn (Bat  (None, 32, 2, 1024)  3072       ['layer14/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer14/depthwise_conv/relu (R  (None, 32, 2, 1024)  0          ['layer14/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer14/pointwise_conv (Conv2D  (None, 32, 2, 1024)  1048576    ['layer14/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer14/pointwise_conv/bn (Bat  (None, 32, 2, 1024)  3072       ['layer14/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer14/pointwise_conv/relu (R  (None, 32, 2, 1024)  0          ['layer14/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_12 (SpatialD  (None, 32, 2, 1024)  0          ['layer14/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " layer15/depthwise_conv (Depthw  (None, 32, 2, 1024)  9216       ['spatial_dropout2d_12[0][0]']   \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer15/depthwise_conv/bn (Bat  (None, 32, 2, 1024)  3072       ['layer15/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer15/depthwise_conv/relu (R  (None, 32, 2, 1024)  0          ['layer15/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer15/pointwise_conv (Conv2D  (None, 32, 2, 512)  524288      ['layer15/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer15/pointwise_conv/bn (Bat  (None, 32, 2, 512)  1536        ['layer15/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer15/pointwise_conv/relu (R  (None, 32, 2, 512)  0           ['layer15/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_13 (SpatialD  (None, 32, 2, 512)  0           ['layer15/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " layer16/depthwise_conv (Depthw  (None, 32, 2, 512)  4608        ['spatial_dropout2d_13[0][0]']   \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer16/depthwise_conv/bn (Bat  (None, 32, 2, 512)  1536        ['layer16/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer16/depthwise_conv/relu (R  (None, 32, 2, 512)  0           ['layer16/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer16/pointwise_conv (Conv2D  (None, 32, 2, 256)  131072      ['layer16/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer16/pointwise_conv/bn (Bat  (None, 32, 2, 256)  768         ['layer16/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer16/pointwise_conv/relu (R  (None, 32, 2, 256)  0           ['layer16/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_14 (SpatialD  (None, 32, 2, 256)  0           ['layer16/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " layer17/depthwise_conv (Depthw  (None, 32, 2, 256)  2304        ['spatial_dropout2d_14[0][0]']   \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " layer17/depthwise_conv/bn (Bat  (None, 32, 2, 256)  768         ['layer17/depthwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer17/depthwise_conv/relu (R  (None, 32, 2, 256)  0           ['layer17/depthwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " layer17/pointwise_conv (Conv2D  (None, 32, 2, 128)  32768       ['layer17/depthwise_conv/relu[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " layer17/pointwise_conv/bn (Bat  (None, 32, 2, 128)  384         ['layer17/pointwise_conv[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer17/pointwise_conv/relu (R  (None, 32, 2, 128)  0           ['layer17/pointwise_conv/bn[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " spatial_dropout2d_15 (SpatialD  (None, 32, 2, 128)  0           ['layer17/pointwise_conv/relu[0][\n",
            " ropout2D)                                                       0]']                             \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 256)      0           ['spatial_dropout2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 32, 30)       7710        ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,021,417\n",
            "Trainable params: 44,994,153\n",
            "Non-trainable params: 27,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_81qYpp-SdFz"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(\"/content/drive/MyDrive/10708 - Project/YOHO-music-speech.h5\") # model-best-error-YamNet.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuPFJ3WGsKtB"
      },
      "source": [
        "### Training based on previously saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hRvzWPhZ6Wb"
      },
      "outputs": [],
      "source": [
        "# run this to load weights for RBM layers \n",
        "\n",
        "rbm_layer_1 = model.get_layer('rbm_1') \n",
        "rbm_layer_2_1 = model.get_layer('rbm_2_1')\n",
        "rbm_layer_2_2 = model.get_layer('rbm_2_2')\n",
        "\n",
        "\n",
        "rbm_1_weights = np.load('/content/drive/MyDrive/10708 - Project/code/saved models/rbm_variables_layer1.npz') \n",
        "rbm_2_1_weights = np.load('/content/drive/MyDrive/10708 - Project/code/saved models/rbm_variables_layer2_700.npz')\n",
        "rbm_2_2_weights = np.load('/content/drive/MyDrive/10708 - Project/code/saved models/rbm_variables_layer2_301.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If9oKMtRk9aX"
      },
      "outputs": [],
      "source": [
        "rbm_layer_1.set_weights([rbm_1_weights['W'], rbm_1_weights['hb']])\n",
        "rbm_layer_2_1.set_weights([rbm_2_1_weights['W'], rbm_2_1_weights['hb']])\n",
        "rbm_layer_2_2.set_weights([rbm_2_2_weights['W'], rbm_2_2_weights['hb']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejEdBCegsJgF"
      },
      "outputs": [],
      "source": [
        "# run this to load model weights without RBM parts\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/10708 - Project/code/saved models/model-best-f1-coh_loss-0d5-rbm2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsGwm1u4gNtO"
      },
      "source": [
        "## CDBN [NO NEED TO RUN]\n",
        " Pre-trained weights have been saved to saved-models in shared drive. Just keep these blocks updated for future use is fine. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amK9KZjbgPuS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class RBM:\n",
        "    def __init__(self, visible_units, hidden_units, learning_rate=0.01, batch_size=10):\n",
        "        self.visible_units = visible_units\n",
        "        self.hidden_units = hidden_units\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        # Initialize weights and biases\n",
        "        self.W = tf.Variable(tf.random.normal([visible_units, hidden_units], mean=0, stddev=0.01), name=\"weights\")\n",
        "        self.vb = tf.Variable(tf.zeros([visible_units]), name=\"visible_bias\")\n",
        "        self.hb = tf.Variable(tf.zeros([hidden_units]), name=\"hidden_bias\")\n",
        "\n",
        "        self.W = tf.cast(self.W,dtype=tf.float64)\n",
        "        self.vb = tf.cast(self.vb,dtype=tf.float64)\n",
        "        self.hb = tf.cast(self.hb,dtype=tf.float64)\n",
        "\n",
        "        self.W = tf.Variable(self.W)\n",
        "        self.vb = tf.Variable(self.vb)\n",
        "        self.hb = tf.Variable(self.hb)\n",
        "\n",
        "    def sample_hidden(self, visible_probabilities):\n",
        "        hidden_activations = tf.nn.sigmoid(tf.matmul(visible_probabilities, self.W) + self.hb)\n",
        "        hidden_samples = tf.nn.relu(tf.sign(hidden_activations - tf.cast(tf.random.uniform(tf.shape(hidden_activations)),dtype=tf.float64)))\n",
        "        return hidden_samples\n",
        "\n",
        "    def sample_visible(self, hidden_probabilities):\n",
        "        visible_activations = tf.nn.sigmoid(tf.matmul(hidden_probabilities, tf.transpose(self.W)) + self.vb)\n",
        "        visible_samples = tf.nn.relu(tf.sign(visible_activations - tf.cast(tf.random.uniform(tf.shape(visible_activations)),dtype=tf.float64)))\n",
        "        return visible_samples\n",
        "\n",
        "    def contrastive_divergence(self, input_data, k=1):\n",
        "        visible_probabilities = input_data\n",
        "        hidden_probabilities = self.sample_hidden(visible_probabilities)\n",
        "        \n",
        "        for _ in range(k):\n",
        "            visible_probabilities = self.sample_visible(hidden_probabilities)\n",
        "            hidden_probabilities = self.sample_hidden(visible_probabilities)\n",
        "\n",
        "        return visible_probabilities\n",
        "\n",
        "    def update_weights(self, input_data, k=1):\n",
        "        positive_hidden_probabilities = self.sample_hidden(input_data)\n",
        "        negative_visible_probabilities = self.contrastive_divergence(input_data, k=k)\n",
        "\n",
        "        positive_associations = tf.matmul(tf.transpose(input_data), positive_hidden_probabilities)\n",
        "        negative_associations = tf.matmul(tf.transpose(negative_visible_probabilities), self.sample_hidden(negative_visible_probabilities))\n",
        "\n",
        "        self.W.assign_add(self.learning_rate * (positive_associations - negative_associations))\n",
        "        self.vb.assign_add(self.learning_rate * tf.reduce_mean(input_data - negative_visible_probabilities, 0))\n",
        "        self.hb.assign_add(self.learning_rate * tf.reduce_mean(positive_hidden_probabilities - self.sample_hidden(negative_visible_probabilities), 0))\n",
        "\n",
        "    def train(self, input_data, epochs=10, k=1):\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch: {epoch+1}/{epochs}\")\n",
        "            flattened_input_data = input_data.reshape(-1, self.visible_units)\n",
        "            self.update_weights(flattened_input_data, k=k)\n",
        "\n",
        "    def train_old(self, training_generator, steps_per_epoch, epochs=10, k=1):\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch: {epoch+1}/{epochs}\")\n",
        "            for step in range(steps_per_epoch):\n",
        "                input_data = next(training_generator)\n",
        "                flattened_input_data = input_data.reshape(-1, self.visible_units)\n",
        "                self.update_weights(flattened_input_data, k=k)\n",
        "\n",
        "    def load_weights(self, weight_file, visible_bias_file, hidden_bias_file):\n",
        "        self.W.assign(np.load(weight_file))\n",
        "        self.vb.assign(np.load(visible_bias_file))\n",
        "        self.hb.assign(np.load(hidden_bias_file))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZHFIdtJgT_8"
      },
      "outputs": [],
      "source": [
        "# input_data = np.random.rand(100, 1001, 40)  # Replace this with your actual input data\n",
        "# flattened_input_data = input_data.reshape(-1, 1001 * 40)\n",
        "\n",
        "data = glob.glob(\"/content/content/train-data/ex-*.npy\")\n",
        "sort_nicely(data)\n",
        "\n",
        "all_data = np.empty((6000,1001,40))\n",
        "idx = 0\n",
        "for file_name in data:\n",
        "  this_data = np.load(file_name)\n",
        "  all_data[idx,:,:] = this_data.reshape(-1,1001,40)  #np.concatenate((all_data, this_data.reshape(-1,1001,40)),axis=0)\n",
        "  idx +=1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWxoY2TYnLQO",
        "outputId": "4e4fe52f-1a1c-4bf8-bbcb-1c58ec67a811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n",
            "Epoch: 2/10\n",
            "Epoch: 3/10\n",
            "Epoch: 4/10\n",
            "Epoch: 5/10\n",
            "Epoch: 6/10\n",
            "Epoch: 7/10\n",
            "Epoch: 8/10\n",
            "Epoch: 9/10\n",
            "Epoch: 10/10\n"
          ]
        }
      ],
      "source": [
        "visible_units = 1001 * 40\n",
        "hidden_units = 1001  # You can adjust this to the desired number of hidden units\n",
        "\n",
        "# Create an RBM layer\n",
        "rbm = RBM(visible_units, hidden_units, learning_rate=0.01, batch_size=10)\n",
        "\n",
        "#steps_per_epoch = 188\n",
        "# Train the RBM layer\n",
        "#all_data = tf.constant(all_data,dtype=tf.float64)\n",
        "#all_data = all_data.numpy()\n",
        "#data_zzz = all_data[:100,:,:]\n",
        "rbm.train(all_data.astype(\"double\"), epochs=10, k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVoRcqt3w-Nq"
      },
      "outputs": [],
      "source": [
        "variables = {'W': rbm.W, 'vb': rbm.vb, 'hb': rbm.hb}\n",
        "#np.savez('rbm_variables.npz', **variables)\n",
        "np.savez_compressed('rbm_variables.npz', **variables)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_input_data = all_data.reshape(-1, 1001 * 40) #all_data = (5000, 1001, 40)\n",
        "input_hidden = rbm.sample_hidden(flattened_input_data) \n",
        "\n",
        "second_visible_units = hidden_units  # The hidden units from the previous RBM layer become the visible units for the next layer\n",
        "second_hidden_units = 700  # Adjust this to the desired number of hidden units for the second RBM layer\n",
        "\n",
        "rbm2 = RBM(second_visible_units, second_hidden_units, learning_rate=0.01, batch_size=10)\n",
        "rbm2.train(input_hidden, epochs=10, k=1)\n",
        "input_hidden2 = rbm2.sample_hidden(input_hidden)"
      ],
      "metadata": {
        "id": "g_Qk9fmnb-OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables2 = {'W': rbm2.W, 'vb': rbm2.vb, 'hb': rbm2.hb}\n",
        "np.savez('/content/drive/MyDrive/10708 - Project/rbm_variables_layer2_700.npz', **variables2)"
      ],
      "metadata": {
        "id": "3QuwfPHacBpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_input_data = all_data.reshape(-1, 1001 * 40) #all_data = (5000, 1001, 40)\n",
        "input_hidden = rbm.sample_hidden(flattened_input_data) \n",
        "\n",
        "second_visible_units = hidden_units  # The hidden units from the previous RBM layer become the visible units for the next layer\n",
        "second_hidden_units = 301  # Adjust this to the desired number of hidden units for the second RBM layer\n",
        "\n",
        "rbm3 = RBM(second_visible_units, second_hidden_units, learning_rate=0.01, batch_size=10)\n",
        "rbm3.train(input_hidden, epochs=10, k=1)\n",
        "input_hidden3 = rbm3.sample_hidden(input_hidden)"
      ],
      "metadata": {
        "id": "I5IhoRkucFKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables3 = {'W': rbm3.W, 'vb': rbm3.vb, 'hb': rbm3.hb}\n",
        "np.savez('/content/drive/MyDrive/10708 - Project/rbm_variables_layer2_301.npz', **variables3)"
      ],
      "metadata": {
        "id": "JfZhSY9lcLZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuTk8RB2Sljx"
      },
      "source": [
        "# 6. Model Training\n",
        "\n",
        "Parameter/settings to play with:\n",
        "\n",
        "- DataGenerator \n",
        "  - batch size\n",
        "  - epoch_size (minibatch? set to 0 for SGD?)\n",
        "- callback\n",
        "  - keras callbacks (e.g. tf.keras.callbacks.EarlyStopping)\n",
        "  - custom callbacks (check previous block for definition)\n",
        "- optimizer \n",
        "  - 2 examples contained in this block, choose the setting we want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l_1kIVaSpPu",
        "outputId": "234b6ce0-5ebf-4485-ca81-33167f735593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constructor called!!!\n",
            "Constructor called!!!\n"
          ]
        }
      ],
      "source": [
        "# Parametersa\n",
        "params = {'dim': (1, ),\n",
        "      'batch_size': 32,\n",
        "      'epoch_size': 5,\n",
        "      'n_classes': 10, # original 2, should be 10? But this seems to be not used in DataGenerator class?\n",
        "      'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], **params)\n",
        "validation_generator = DataGenerator(partition['validation'], **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmpN7uoLSxNS"
      },
      "outputs": [],
      "source": [
        "#callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1K0Kn1wS0aS"
      },
      "outputs": [],
      "source": [
        "m_auc = tf.keras.metrics.AUC(\n",
        "    num_thresholds=200,\n",
        "    curve=\"ROC\",\n",
        "    summation_method=\"interpolation\",\n",
        "    multi_label=True,\n",
        "    num_labels=162,\n",
        "    # label_weights=[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
        "    from_logits=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK-P3UF5S05J"
      },
      "outputs": [],
      "source": [
        "# compile model with optimizer setting 1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=1e-2,\n",
        "        decay_steps=250,\n",
        "        decay_rate=0.9)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "model.compile(optimizer=optimizer, loss=my_loss_fn, metrics=[binary_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5-AXTlTS3JN"
      },
      "outputs": [],
      "source": [
        "# compile model with optimizer setting 2\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=my_loss_fn, metrics=[binary_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV7Aa7p665SM",
        "outputId": "ca11d585-30c7-4240-a62f-393f327c7b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "63/63 [==============================] - 87s 1s/step\n",
            "F-measure: 0.544 vs 0.544\n",
            "Error rate: 0.580 vs 0.580\n",
            "187/187 - 1792s - loss: 17.9932 - binary_acc: 0.9466 - val_loss: 22.7221 - val_binary_acc: 0.9264 - 1792s/epoch - 10s/step\n",
            "Epoch 2/1000\n",
            "63/63 [==============================] - 85s 1s/step\n",
            "F-measure: 0.548 vs 0.548\n",
            "Error rate: 0.575 vs 0.575\n",
            "187/187 - 1796s - loss: 17.8268 - binary_acc: 0.9472 - val_loss: 23.3130 - val_binary_acc: 0.9240 - 1796s/epoch - 10s/step\n",
            "Epoch 3/1000\n",
            "63/63 [==============================] - 81s 1s/step\n",
            "F-measure: 0.555 vs 0.555\n",
            "Error rate: 0.571 vs 0.571\n",
            "187/187 - 1747s - loss: 17.9094 - binary_acc: 0.9468 - val_loss: 22.3620 - val_binary_acc: 0.9274 - 1747s/epoch - 9s/step\n",
            "Epoch 4/1000\n",
            "63/63 [==============================] - 81s 1s/step\n",
            "F-measure: 0.557 vs 0.557\n",
            "Error rate: 0.566 vs 0.566\n",
            "187/187 - 1746s - loss: 17.8882 - binary_acc: 0.9470 - val_loss: 22.8096 - val_binary_acc: 0.9266 - 1746s/epoch - 9s/step\n",
            "Epoch 5/1000\n",
            "63/63 [==============================] - 81s 1s/step\n",
            "F-measure: 0.555 vs 0.557\n",
            "Error rate: 0.567 vs 0.566\n",
            "187/187 - 1717s - loss: 17.9799 - binary_acc: 0.9468 - val_loss: 23.0042 - val_binary_acc: 0.9251 - 1717s/epoch - 9s/step\n",
            "Epoch 6/1000\n",
            "63/63 [==============================] - 82s 1s/step\n",
            "F-measure: 0.558 vs 0.558\n",
            "Error rate: 0.569 vs 0.566\n",
            "187/187 - 1742s - loss: 17.9491 - binary_acc: 0.9468 - val_loss: 23.0867 - val_binary_acc: 0.9247 - 1742s/epoch - 9s/step\n",
            "Epoch 7/1000\n",
            "63/63 [==============================] - 80s 1s/step\n",
            "F-measure: 0.540 vs 0.558\n",
            "Error rate: 0.585 vs 0.566\n",
            "187/187 - 1714s - loss: 17.9175 - binary_acc: 0.9469 - val_loss: 22.9086 - val_binary_acc: 0.9256 - 1714s/epoch - 9s/step\n",
            "Epoch 8/1000\n",
            "63/63 [==============================] - 84s 1s/step\n",
            "F-measure: 0.538 vs 0.558\n",
            "Error rate: 0.584 vs 0.566\n",
            "187/187 - 1612s - loss: 17.8232 - binary_acc: 0.9471 - val_loss: 23.1916 - val_binary_acc: 0.9242 - 1612s/epoch - 9s/step\n",
            "Epoch 9/1000\n"
          ]
        }
      ],
      "source": [
        "# coh_loss = 0.1, load weights from coh_loss = 0.5 since run out of GPU time\n",
        "model.fit(training_generator, validation_data=validation_generator, epochs=1000, callbacks=[MyCustomCallback_44()], verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8JzTyHm3Bzt",
        "outputId": "4a6e4579-1ddd-4c27-facb-ea2db333496b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "63/63 [==============================] - 3s 31ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 85s - loss: 83.6491 - binary_acc: 0.9148 - val_loss: 92.8042 - val_binary_acc: 0.9213 - 85s/epoch - 457ms/step\n",
            "Epoch 2/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 45s - loss: 62.3356 - binary_acc: 0.9197 - val_loss: 66.6647 - val_binary_acc: 0.9213 - 45s/epoch - 241ms/step\n",
            "Epoch 3/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 44s - loss: 49.3521 - binary_acc: 0.9199 - val_loss: 48.2002 - val_binary_acc: 0.9214 - 44s/epoch - 237ms/step\n",
            "Epoch 4/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.002 vs 0.002\n",
            "Error rate: 0.999 vs 0.999\n",
            "187/187 - 49s - loss: 41.6526 - binary_acc: 0.9207 - val_loss: 41.9937 - val_binary_acc: 0.9211 - 49s/epoch - 262ms/step\n",
            "Epoch 5/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.131 vs 0.131\n",
            "Error rate: 0.928 vs 0.928\n",
            "187/187 - 50s - loss: 36.7147 - binary_acc: 0.9214 - val_loss: 37.1094 - val_binary_acc: 0.9205 - 50s/epoch - 265ms/step\n",
            "Epoch 6/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.194 vs 0.194\n",
            "Error rate: 0.887 vs 0.887\n",
            "187/187 - 51s - loss: 33.2706 - binary_acc: 0.9225 - val_loss: 33.1783 - val_binary_acc: 0.9188 - 51s/epoch - 272ms/step\n",
            "Epoch 7/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.249 vs 0.249\n",
            "Error rate: 0.850 vs 0.850\n",
            "187/187 - 50s - loss: 30.8005 - binary_acc: 0.9233 - val_loss: 30.7038 - val_binary_acc: 0.9208 - 50s/epoch - 270ms/step\n",
            "Epoch 8/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.245 vs 0.249\n",
            "Error rate: 0.854 vs 0.850\n",
            "187/187 - 45s - loss: 29.1181 - binary_acc: 0.9236 - val_loss: 28.9764 - val_binary_acc: 0.9221 - 45s/epoch - 243ms/step\n",
            "Epoch 9/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.259 vs 0.259\n",
            "Error rate: 0.842 vs 0.842\n",
            "187/187 - 50s - loss: 27.6837 - binary_acc: 0.9245 - val_loss: 28.0581 - val_binary_acc: 0.9206 - 50s/epoch - 265ms/step\n",
            "Epoch 10/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.270 vs 0.270\n",
            "Error rate: 0.834 vs 0.834\n",
            "187/187 - 50s - loss: 26.5989 - binary_acc: 0.9250 - val_loss: 27.9629 - val_binary_acc: 0.9187 - 50s/epoch - 270ms/step\n",
            "Epoch 11/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.347 vs 0.347\n",
            "Error rate: 0.769 vs 0.769\n",
            "187/187 - 52s - loss: 25.8090 - binary_acc: 0.9254 - val_loss: 27.0060 - val_binary_acc: 0.9204 - 52s/epoch - 277ms/step\n",
            "Epoch 12/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.338 vs 0.347\n",
            "Error rate: 0.778 vs 0.769\n",
            "187/187 - 50s - loss: 25.2149 - binary_acc: 0.9259 - val_loss: 26.5796 - val_binary_acc: 0.9207 - 50s/epoch - 269ms/step\n",
            "Epoch 13/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.309 vs 0.347\n",
            "Error rate: 0.797 vs 0.769\n",
            "187/187 - 45s - loss: 24.5842 - binary_acc: 0.9274 - val_loss: 26.7510 - val_binary_acc: 0.9191 - 45s/epoch - 242ms/step\n",
            "Epoch 14/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.372 vs 0.372\n",
            "Error rate: 0.748 vs 0.748\n",
            "187/187 - 51s - loss: 24.2070 - binary_acc: 0.9279 - val_loss: 25.5174 - val_binary_acc: 0.9219 - 51s/epoch - 270ms/step\n",
            "Epoch 15/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.403 vs 0.403\n",
            "Error rate: 0.710 vs 0.710\n",
            "187/187 - 51s - loss: 23.7374 - binary_acc: 0.9292 - val_loss: 27.4699 - val_binary_acc: 0.9143 - 51s/epoch - 271ms/step\n",
            "Epoch 16/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.416 vs 0.416\n",
            "Error rate: 0.709 vs 0.709\n",
            "187/187 - 53s - loss: 23.3675 - binary_acc: 0.9299 - val_loss: 25.9779 - val_binary_acc: 0.9180 - 53s/epoch - 286ms/step\n",
            "Epoch 17/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.432 vs 0.432\n",
            "Error rate: 0.692 vs 0.692\n",
            "187/187 - 54s - loss: 23.0700 - binary_acc: 0.9307 - val_loss: 25.2722 - val_binary_acc: 0.9209 - 54s/epoch - 290ms/step\n",
            "Epoch 18/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.428 vs 0.432\n",
            "Error rate: 0.700 vs 0.692\n",
            "187/187 - 45s - loss: 22.6949 - binary_acc: 0.9317 - val_loss: 24.7839 - val_binary_acc: 0.9232 - 45s/epoch - 243ms/step\n",
            "Epoch 19/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.439 vs 0.439\n",
            "Error rate: 0.678 vs 0.678\n",
            "187/187 - 55s - loss: 22.5087 - binary_acc: 0.9321 - val_loss: 26.1047 - val_binary_acc: 0.9183 - 55s/epoch - 296ms/step\n",
            "Epoch 20/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.458 vs 0.458\n",
            "Error rate: 0.668 vs 0.668\n",
            "187/187 - 53s - loss: 22.3731 - binary_acc: 0.9327 - val_loss: 24.5768 - val_binary_acc: 0.9228 - 53s/epoch - 283ms/step\n",
            "Epoch 21/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.464 vs 0.464\n",
            "Error rate: 0.657 vs 0.657\n",
            "187/187 - 52s - loss: 22.0227 - binary_acc: 0.9333 - val_loss: 24.5660 - val_binary_acc: 0.9216 - 52s/epoch - 279ms/step\n",
            "Epoch 22/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.432 vs 0.464\n",
            "Error rate: 0.683 vs 0.657\n",
            "187/187 - 48s - loss: 21.8899 - binary_acc: 0.9336 - val_loss: 25.7133 - val_binary_acc: 0.9184 - 48s/epoch - 256ms/step\n",
            "Epoch 23/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.452 vs 0.464\n",
            "Error rate: 0.670 vs 0.657\n",
            "187/187 - 47s - loss: 21.5749 - binary_acc: 0.9346 - val_loss: 24.7006 - val_binary_acc: 0.9209 - 47s/epoch - 251ms/step\n",
            "Epoch 24/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.440 vs 0.464\n",
            "Error rate: 0.681 vs 0.657\n",
            "187/187 - 50s - loss: 21.5785 - binary_acc: 0.9347 - val_loss: 25.0653 - val_binary_acc: 0.9200 - 50s/epoch - 267ms/step\n",
            "Epoch 25/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.483 vs 0.483\n",
            "Error rate: 0.640 vs 0.640\n",
            "187/187 - 51s - loss: 21.4620 - binary_acc: 0.9351 - val_loss: 24.6573 - val_binary_acc: 0.9210 - 51s/epoch - 275ms/step\n",
            "Epoch 26/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.488 vs 0.488\n",
            "Error rate: 0.642 vs 0.640\n",
            "187/187 - 50s - loss: 21.2934 - binary_acc: 0.9357 - val_loss: 24.2824 - val_binary_acc: 0.9235 - 50s/epoch - 267ms/step\n",
            "Epoch 27/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.455 vs 0.488\n",
            "Error rate: 0.662 vs 0.640\n",
            "187/187 - 47s - loss: 21.1499 - binary_acc: 0.9363 - val_loss: 25.6567 - val_binary_acc: 0.9170 - 47s/epoch - 252ms/step\n",
            "Epoch 28/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.485 vs 0.488\n",
            "Error rate: 0.637 vs 0.637\n",
            "187/187 - 52s - loss: 21.0516 - binary_acc: 0.9366 - val_loss: 24.9733 - val_binary_acc: 0.9193 - 52s/epoch - 279ms/step\n",
            "Epoch 29/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.507 vs 0.507\n",
            "Error rate: 0.617 vs 0.617\n",
            "187/187 - 51s - loss: 20.9917 - binary_acc: 0.9364 - val_loss: 23.7204 - val_binary_acc: 0.9241 - 51s/epoch - 271ms/step\n",
            "Epoch 30/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.507 vs 0.507\n",
            "Error rate: 0.617 vs 0.617\n",
            "187/187 - 53s - loss: 20.8574 - binary_acc: 0.9369 - val_loss: 24.4151 - val_binary_acc: 0.9217 - 53s/epoch - 282ms/step\n",
            "Epoch 31/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.463 vs 0.507\n",
            "Error rate: 0.654 vs 0.617\n",
            "187/187 - 49s - loss: 20.8100 - binary_acc: 0.9372 - val_loss: 24.7238 - val_binary_acc: 0.9194 - 49s/epoch - 264ms/step\n",
            "Epoch 32/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.500 vs 0.507\n",
            "Error rate: 0.624 vs 0.617\n",
            "187/187 - 46s - loss: 20.6410 - binary_acc: 0.9379 - val_loss: 24.0399 - val_binary_acc: 0.9230 - 46s/epoch - 247ms/step\n",
            "Epoch 33/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.464 vs 0.507\n",
            "Error rate: 0.655 vs 0.617\n",
            "187/187 - 47s - loss: 20.6344 - binary_acc: 0.9379 - val_loss: 25.4554 - val_binary_acc: 0.9181 - 47s/epoch - 251ms/step\n",
            "Epoch 34/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.496 vs 0.507\n",
            "Error rate: 0.632 vs 0.617\n",
            "187/187 - 49s - loss: 20.4890 - binary_acc: 0.9380 - val_loss: 23.7325 - val_binary_acc: 0.9244 - 49s/epoch - 263ms/step\n",
            "Epoch 35/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.480 vs 0.507\n",
            "Error rate: 0.643 vs 0.617\n",
            "187/187 - 47s - loss: 20.4569 - binary_acc: 0.9386 - val_loss: 24.3911 - val_binary_acc: 0.9211 - 47s/epoch - 254ms/step\n",
            "Epoch 36/1000\n",
            "63/63 [==============================] - 2s 29ms/step\n",
            "F-measure: 0.479 vs 0.507\n",
            "Error rate: 0.645 vs 0.617\n",
            "187/187 - 47s - loss: 20.4356 - binary_acc: 0.9385 - val_loss: 24.4142 - val_binary_acc: 0.9215 - 47s/epoch - 249ms/step\n",
            "Epoch 37/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.469 vs 0.507\n",
            "Error rate: 0.652 vs 0.617\n",
            "187/187 - 49s - loss: 20.2755 - binary_acc: 0.9391 - val_loss: 24.8699 - val_binary_acc: 0.9200 - 49s/epoch - 265ms/step\n",
            "Epoch 38/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.491 vs 0.507\n",
            "Error rate: 0.633 vs 0.617\n",
            "187/187 - 47s - loss: 20.2174 - binary_acc: 0.9392 - val_loss: 24.1915 - val_binary_acc: 0.9219 - 47s/epoch - 249ms/step\n",
            "Epoch 39/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.501 vs 0.507\n",
            "Error rate: 0.630 vs 0.617\n",
            "187/187 - 47s - loss: 20.0777 - binary_acc: 0.9397 - val_loss: 23.2723 - val_binary_acc: 0.9251 - 47s/epoch - 249ms/step\n",
            "Epoch 40/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.506 vs 0.507\n",
            "Error rate: 0.619 vs 0.617\n",
            "187/187 - 47s - loss: 20.0635 - binary_acc: 0.9398 - val_loss: 24.4021 - val_binary_acc: 0.9210 - 47s/epoch - 249ms/step\n",
            "Epoch 41/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.474 vs 0.507\n",
            "Error rate: 0.650 vs 0.617\n",
            "187/187 - 47s - loss: 19.9354 - binary_acc: 0.9402 - val_loss: 24.0472 - val_binary_acc: 0.9225 - 47s/epoch - 252ms/step\n",
            "Epoch 42/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.485 vs 0.507\n",
            "Error rate: 0.639 vs 0.617\n",
            "187/187 - 45s - loss: 19.9246 - binary_acc: 0.9402 - val_loss: 23.7510 - val_binary_acc: 0.9236 - 45s/epoch - 242ms/step\n",
            "Epoch 43/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.497 vs 0.507\n",
            "Error rate: 0.625 vs 0.617\n",
            "187/187 - 49s - loss: 19.8422 - binary_acc: 0.9407 - val_loss: 24.3564 - val_binary_acc: 0.9205 - 49s/epoch - 262ms/step\n",
            "Epoch 44/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.493 vs 0.507\n",
            "Error rate: 0.631 vs 0.617\n",
            "187/187 - 45s - loss: 19.9350 - binary_acc: 0.9401 - val_loss: 24.0084 - val_binary_acc: 0.9231 - 45s/epoch - 243ms/step\n",
            "Epoch 45/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.514 vs 0.514\n",
            "Error rate: 0.610 vs 0.610\n",
            "187/187 - 51s - loss: 19.7590 - binary_acc: 0.9410 - val_loss: 23.5032 - val_binary_acc: 0.9245 - 51s/epoch - 275ms/step\n",
            "Epoch 46/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.501 vs 0.514\n",
            "Error rate: 0.623 vs 0.610\n",
            "187/187 - 49s - loss: 19.7495 - binary_acc: 0.9406 - val_loss: 23.9942 - val_binary_acc: 0.9216 - 49s/epoch - 265ms/step\n",
            "Epoch 47/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.515 vs 0.515\n",
            "Error rate: 0.612 vs 0.610\n",
            "187/187 - 48s - loss: 19.6406 - binary_acc: 0.9408 - val_loss: 23.1062 - val_binary_acc: 0.9260 - 48s/epoch - 255ms/step\n",
            "Epoch 48/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.504 vs 0.515\n",
            "Error rate: 0.625 vs 0.610\n",
            "187/187 - 47s - loss: 19.5617 - binary_acc: 0.9413 - val_loss: 23.3970 - val_binary_acc: 0.9237 - 47s/epoch - 251ms/step\n",
            "Epoch 49/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.465 vs 0.515\n",
            "Error rate: 0.654 vs 0.610\n",
            "187/187 - 46s - loss: 19.5691 - binary_acc: 0.9415 - val_loss: 25.3456 - val_binary_acc: 0.9160 - 46s/epoch - 245ms/step\n",
            "Epoch 50/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.464 vs 0.515\n",
            "Error rate: 0.657 vs 0.610\n",
            "187/187 - 46s - loss: 19.5436 - binary_acc: 0.9416 - val_loss: 24.3675 - val_binary_acc: 0.9208 - 46s/epoch - 247ms/step\n",
            "Epoch 51/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.528 vs 0.528\n",
            "Error rate: 0.599 vs 0.599\n",
            "187/187 - 51s - loss: 19.4600 - binary_acc: 0.9419 - val_loss: 23.2386 - val_binary_acc: 0.9256 - 51s/epoch - 271ms/step\n",
            "Epoch 52/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.516 vs 0.528\n",
            "Error rate: 0.606 vs 0.599\n",
            "187/187 - 46s - loss: 19.4990 - binary_acc: 0.9418 - val_loss: 23.6579 - val_binary_acc: 0.9228 - 46s/epoch - 244ms/step\n",
            "Epoch 53/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.505 vs 0.528\n",
            "Error rate: 0.619 vs 0.599\n",
            "187/187 - 45s - loss: 19.4652 - binary_acc: 0.9419 - val_loss: 23.6792 - val_binary_acc: 0.9237 - 45s/epoch - 240ms/step\n",
            "Epoch 54/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.529 vs 0.529\n",
            "Error rate: 0.596 vs 0.596\n",
            "187/187 - 50s - loss: 19.3820 - binary_acc: 0.9421 - val_loss: 23.5831 - val_binary_acc: 0.9245 - 50s/epoch - 270ms/step\n",
            "Epoch 55/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.502 vs 0.529\n",
            "Error rate: 0.618 vs 0.596\n",
            "187/187 - 46s - loss: 19.3813 - binary_acc: 0.9420 - val_loss: 24.1266 - val_binary_acc: 0.9209 - 46s/epoch - 245ms/step\n",
            "Epoch 56/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.510 vs 0.529\n",
            "Error rate: 0.620 vs 0.596\n",
            "187/187 - 47s - loss: 19.3556 - binary_acc: 0.9422 - val_loss: 23.6602 - val_binary_acc: 0.9252 - 47s/epoch - 250ms/step\n",
            "Epoch 57/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.522 vs 0.529\n",
            "Error rate: 0.601 vs 0.596\n",
            "187/187 - 45s - loss: 19.2502 - binary_acc: 0.9427 - val_loss: 23.4356 - val_binary_acc: 0.9233 - 45s/epoch - 240ms/step\n",
            "Epoch 58/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.489 vs 0.529\n",
            "Error rate: 0.635 vs 0.596\n",
            "187/187 - 46s - loss: 19.2920 - binary_acc: 0.9424 - val_loss: 23.8411 - val_binary_acc: 0.9226 - 46s/epoch - 246ms/step\n",
            "Epoch 59/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.495 vs 0.529\n",
            "Error rate: 0.628 vs 0.596\n",
            "187/187 - 46s - loss: 19.0571 - binary_acc: 0.9430 - val_loss: 23.3708 - val_binary_acc: 0.9248 - 46s/epoch - 247ms/step\n",
            "Epoch 60/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.504 vs 0.529\n",
            "Error rate: 0.620 vs 0.596\n",
            "187/187 - 47s - loss: 19.1122 - binary_acc: 0.9429 - val_loss: 23.8935 - val_binary_acc: 0.9229 - 47s/epoch - 251ms/step\n",
            "Epoch 61/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.504 vs 0.529\n",
            "Error rate: 0.620 vs 0.596\n",
            "187/187 - 46s - loss: 19.1621 - binary_acc: 0.9428 - val_loss: 24.2267 - val_binary_acc: 0.9223 - 46s/epoch - 246ms/step\n",
            "Epoch 62/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.498 vs 0.529\n",
            "Error rate: 0.629 vs 0.596\n",
            "187/187 - 46s - loss: 19.1786 - binary_acc: 0.9430 - val_loss: 23.7016 - val_binary_acc: 0.9242 - 46s/epoch - 247ms/step\n",
            "Epoch 63/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.520 vs 0.529\n",
            "Error rate: 0.608 vs 0.596\n",
            "187/187 - 46s - loss: 19.2305 - binary_acc: 0.9425 - val_loss: 23.5216 - val_binary_acc: 0.9238 - 46s/epoch - 249ms/step\n",
            "Epoch 64/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.497 vs 0.529\n",
            "Error rate: 0.626 vs 0.596\n",
            "187/187 - 46s - loss: 19.0004 - binary_acc: 0.9434 - val_loss: 23.5925 - val_binary_acc: 0.9241 - 46s/epoch - 248ms/step\n",
            "Epoch 65/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.523 vs 0.529\n",
            "Error rate: 0.604 vs 0.596\n",
            "187/187 - 45s - loss: 18.9777 - binary_acc: 0.9436 - val_loss: 23.3138 - val_binary_acc: 0.9250 - 45s/epoch - 243ms/step\n",
            "Epoch 66/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.525 vs 0.529\n",
            "Error rate: 0.598 vs 0.596\n",
            "187/187 - 46s - loss: 19.0201 - binary_acc: 0.9432 - val_loss: 23.8759 - val_binary_acc: 0.9224 - 46s/epoch - 246ms/step\n",
            "Epoch 67/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.523 vs 0.529\n",
            "Error rate: 0.604 vs 0.596\n",
            "187/187 - 45s - loss: 19.0009 - binary_acc: 0.9432 - val_loss: 23.0870 - val_binary_acc: 0.9257 - 45s/epoch - 240ms/step\n",
            "Epoch 68/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.534 vs 0.534\n",
            "Error rate: 0.591 vs 0.591\n",
            "187/187 - 50s - loss: 18.9152 - binary_acc: 0.9436 - val_loss: 23.2974 - val_binary_acc: 0.9251 - 50s/epoch - 266ms/step\n",
            "Epoch 69/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.539 vs 0.539\n",
            "Error rate: 0.586 vs 0.586\n",
            "187/187 - 54s - loss: 18.8862 - binary_acc: 0.9439 - val_loss: 23.2865 - val_binary_acc: 0.9248 - 54s/epoch - 289ms/step\n",
            "Epoch 70/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.521 vs 0.539\n",
            "Error rate: 0.603 vs 0.586\n",
            "187/187 - 47s - loss: 18.9307 - binary_acc: 0.9436 - val_loss: 23.7472 - val_binary_acc: 0.9229 - 47s/epoch - 251ms/step\n",
            "Epoch 71/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.513 vs 0.539\n",
            "Error rate: 0.612 vs 0.586\n",
            "187/187 - 49s - loss: 18.8816 - binary_acc: 0.9440 - val_loss: 23.5942 - val_binary_acc: 0.9234 - 49s/epoch - 263ms/step\n",
            "Epoch 72/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.506 vs 0.539\n",
            "Error rate: 0.619 vs 0.586\n",
            "187/187 - 45s - loss: 18.9261 - binary_acc: 0.9438 - val_loss: 23.7053 - val_binary_acc: 0.9241 - 45s/epoch - 242ms/step\n",
            "Epoch 73/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.539 vs 0.539\n",
            "Error rate: 0.587 vs 0.586\n",
            "187/187 - 46s - loss: 18.7085 - binary_acc: 0.9444 - val_loss: 23.4069 - val_binary_acc: 0.9228 - 46s/epoch - 247ms/step\n",
            "Epoch 74/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.542 vs 0.542\n",
            "Error rate: 0.585 vs 0.585\n",
            "187/187 - 51s - loss: 18.7480 - binary_acc: 0.9441 - val_loss: 22.7978 - val_binary_acc: 0.9269 - 51s/epoch - 270ms/step\n",
            "Epoch 75/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.535 vs 0.542\n",
            "Error rate: 0.591 vs 0.585\n",
            "187/187 - 47s - loss: 18.6676 - binary_acc: 0.9445 - val_loss: 23.7639 - val_binary_acc: 0.9232 - 47s/epoch - 250ms/step\n",
            "Epoch 76/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.531 vs 0.542\n",
            "Error rate: 0.591 vs 0.585\n",
            "187/187 - 45s - loss: 18.6179 - binary_acc: 0.9444 - val_loss: 23.4870 - val_binary_acc: 0.9240 - 45s/epoch - 243ms/step\n",
            "Epoch 77/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.524 vs 0.542\n",
            "Error rate: 0.597 vs 0.585\n",
            "187/187 - 46s - loss: 18.5420 - binary_acc: 0.9447 - val_loss: 23.6592 - val_binary_acc: 0.9227 - 46s/epoch - 246ms/step\n",
            "Epoch 78/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.524 vs 0.542\n",
            "Error rate: 0.597 vs 0.585\n",
            "187/187 - 45s - loss: 18.6369 - binary_acc: 0.9444 - val_loss: 23.4644 - val_binary_acc: 0.9233 - 45s/epoch - 240ms/step\n",
            "Epoch 79/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.539 vs 0.542\n",
            "Error rate: 0.585 vs 0.585\n",
            "187/187 - 49s - loss: 18.7103 - binary_acc: 0.9442 - val_loss: 22.9469 - val_binary_acc: 0.9261 - 49s/epoch - 261ms/step\n",
            "Epoch 80/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.528 vs 0.542\n",
            "Error rate: 0.600 vs 0.585\n",
            "187/187 - 47s - loss: 18.6576 - binary_acc: 0.9446 - val_loss: 23.4879 - val_binary_acc: 0.9232 - 47s/epoch - 249ms/step\n",
            "Epoch 81/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.506 vs 0.542\n",
            "Error rate: 0.617 vs 0.585\n",
            "187/187 - 47s - loss: 18.6848 - binary_acc: 0.9445 - val_loss: 23.7357 - val_binary_acc: 0.9221 - 47s/epoch - 251ms/step\n",
            "Epoch 82/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.532 vs 0.542\n",
            "Error rate: 0.594 vs 0.585\n",
            "187/187 - 45s - loss: 18.5690 - binary_acc: 0.9448 - val_loss: 23.0020 - val_binary_acc: 0.9251 - 45s/epoch - 241ms/step\n",
            "Epoch 83/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.526 vs 0.542\n",
            "Error rate: 0.598 vs 0.585\n",
            "187/187 - 46s - loss: 18.4438 - binary_acc: 0.9453 - val_loss: 23.3977 - val_binary_acc: 0.9251 - 46s/epoch - 246ms/step\n",
            "Epoch 84/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.550 vs 0.550\n",
            "Error rate: 0.575 vs 0.575\n",
            "187/187 - 49s - loss: 18.5882 - binary_acc: 0.9445 - val_loss: 22.9706 - val_binary_acc: 0.9257 - 49s/epoch - 264ms/step\n",
            "Epoch 85/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.548 vs 0.550\n",
            "Error rate: 0.575 vs 0.575\n",
            "187/187 - 51s - loss: 18.6567 - binary_acc: 0.9443 - val_loss: 23.1772 - val_binary_acc: 0.9246 - 51s/epoch - 273ms/step\n",
            "Epoch 86/1000\n",
            "63/63 [==============================] - 2s 28ms/step\n",
            "F-measure: 0.526 vs 0.550\n",
            "Error rate: 0.593 vs 0.575\n",
            "187/187 - 46s - loss: 18.5826 - binary_acc: 0.9448 - val_loss: 24.2345 - val_binary_acc: 0.9207 - 46s/epoch - 247ms/step\n",
            "Epoch 87/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.527 vs 0.550\n",
            "Error rate: 0.597 vs 0.575\n",
            "187/187 - 47s - loss: 18.7097 - binary_acc: 0.9446 - val_loss: 23.3484 - val_binary_acc: 0.9243 - 47s/epoch - 250ms/step\n",
            "Epoch 88/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.539 vs 0.550\n",
            "Error rate: 0.584 vs 0.575\n",
            "187/187 - 45s - loss: 18.4591 - binary_acc: 0.9450 - val_loss: 23.1639 - val_binary_acc: 0.9253 - 45s/epoch - 239ms/step\n",
            "Epoch 89/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.546 vs 0.550\n",
            "Error rate: 0.580 vs 0.575\n",
            "187/187 - 47s - loss: 18.4033 - binary_acc: 0.9451 - val_loss: 23.0098 - val_binary_acc: 0.9257 - 47s/epoch - 252ms/step\n",
            "Epoch 90/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.540 vs 0.550\n",
            "Error rate: 0.584 vs 0.575\n",
            "187/187 - 45s - loss: 18.4375 - binary_acc: 0.9452 - val_loss: 22.9502 - val_binary_acc: 0.9266 - 45s/epoch - 242ms/step\n",
            "Epoch 91/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.542 vs 0.550\n",
            "Error rate: 0.579 vs 0.575\n",
            "187/187 - 46s - loss: 18.4941 - binary_acc: 0.9449 - val_loss: 23.3194 - val_binary_acc: 0.9236 - 46s/epoch - 245ms/step\n",
            "Epoch 92/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.527 vs 0.550\n",
            "Error rate: 0.593 vs 0.575\n",
            "187/187 - 46s - loss: 18.3600 - binary_acc: 0.9454 - val_loss: 23.7004 - val_binary_acc: 0.9233 - 46s/epoch - 248ms/step\n",
            "Epoch 93/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.533 vs 0.550\n",
            "Error rate: 0.592 vs 0.575\n",
            "187/187 - 47s - loss: 18.5044 - binary_acc: 0.9450 - val_loss: 23.4474 - val_binary_acc: 0.9240 - 47s/epoch - 254ms/step\n",
            "Epoch 94/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.557 vs 0.557\n",
            "Error rate: 0.568 vs 0.568\n",
            "187/187 - 51s - loss: 18.3117 - binary_acc: 0.9455 - val_loss: 23.0490 - val_binary_acc: 0.9255 - 51s/epoch - 271ms/step\n",
            "Epoch 95/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.525 vs 0.557\n",
            "Error rate: 0.593 vs 0.568\n",
            "187/187 - 45s - loss: 18.3291 - binary_acc: 0.9457 - val_loss: 23.6639 - val_binary_acc: 0.9224 - 45s/epoch - 243ms/step\n",
            "Epoch 96/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.550 vs 0.557\n",
            "Error rate: 0.573 vs 0.568\n",
            "187/187 - 46s - loss: 18.3445 - binary_acc: 0.9456 - val_loss: 22.9530 - val_binary_acc: 0.9258 - 46s/epoch - 245ms/step\n",
            "Epoch 97/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.537 vs 0.557\n",
            "Error rate: 0.586 vs 0.568\n",
            "187/187 - 45s - loss: 18.4087 - binary_acc: 0.9451 - val_loss: 23.2715 - val_binary_acc: 0.9253 - 45s/epoch - 241ms/step\n",
            "Epoch 98/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.544 vs 0.557\n",
            "Error rate: 0.579 vs 0.568\n",
            "187/187 - 47s - loss: 18.2996 - binary_acc: 0.9457 - val_loss: 23.5735 - val_binary_acc: 0.9217 - 47s/epoch - 252ms/step\n",
            "Epoch 99/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.559 vs 0.559\n",
            "Error rate: 0.564 vs 0.564\n",
            "187/187 - 50s - loss: 18.2059 - binary_acc: 0.9460 - val_loss: 23.0425 - val_binary_acc: 0.9256 - 50s/epoch - 266ms/step\n",
            "Epoch 100/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.512 vs 0.559\n",
            "Error rate: 0.609 vs 0.564\n",
            "187/187 - 46s - loss: 18.2999 - binary_acc: 0.9456 - val_loss: 23.5048 - val_binary_acc: 0.9231 - 46s/epoch - 244ms/step\n",
            "Epoch 101/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.559\n",
            "Error rate: 0.569 vs 0.564\n",
            "187/187 - 45s - loss: 18.2357 - binary_acc: 0.9458 - val_loss: 22.8996 - val_binary_acc: 0.9254 - 45s/epoch - 240ms/step\n",
            "Epoch 102/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.533 vs 0.559\n",
            "Error rate: 0.587 vs 0.564\n",
            "187/187 - 46s - loss: 18.2360 - binary_acc: 0.9455 - val_loss: 23.5170 - val_binary_acc: 0.9229 - 46s/epoch - 248ms/step\n",
            "Epoch 103/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.558 vs 0.559\n",
            "Error rate: 0.566 vs 0.564\n",
            "187/187 - 45s - loss: 18.2745 - binary_acc: 0.9457 - val_loss: 22.8423 - val_binary_acc: 0.9270 - 45s/epoch - 238ms/step\n",
            "Epoch 104/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.527 vs 0.559\n",
            "Error rate: 0.594 vs 0.564\n",
            "187/187 - 47s - loss: 18.1894 - binary_acc: 0.9462 - val_loss: 23.6749 - val_binary_acc: 0.9223 - 47s/epoch - 250ms/step\n",
            "Epoch 105/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.556 vs 0.559\n",
            "Error rate: 0.570 vs 0.564\n",
            "187/187 - 47s - loss: 18.2794 - binary_acc: 0.9458 - val_loss: 22.7123 - val_binary_acc: 0.9259 - 47s/epoch - 252ms/step\n",
            "Epoch 106/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.551 vs 0.559\n",
            "Error rate: 0.572 vs 0.564\n",
            "187/187 - 47s - loss: 18.1747 - binary_acc: 0.9462 - val_loss: 23.3419 - val_binary_acc: 0.9242 - 47s/epoch - 251ms/step\n",
            "Epoch 107/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.536 vs 0.559\n",
            "Error rate: 0.590 vs 0.564\n",
            "187/187 - 45s - loss: 18.2201 - binary_acc: 0.9460 - val_loss: 23.5688 - val_binary_acc: 0.9234 - 45s/epoch - 239ms/step\n",
            "Epoch 108/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.532 vs 0.559\n",
            "Error rate: 0.589 vs 0.564\n",
            "187/187 - 47s - loss: 18.3300 - binary_acc: 0.9456 - val_loss: 23.5977 - val_binary_acc: 0.9234 - 47s/epoch - 250ms/step\n",
            "Epoch 109/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.538 vs 0.559\n",
            "Error rate: 0.584 vs 0.564\n",
            "187/187 - 45s - loss: 18.2905 - binary_acc: 0.9458 - val_loss: 23.1268 - val_binary_acc: 0.9248 - 45s/epoch - 239ms/step\n",
            "Epoch 110/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.553 vs 0.559\n",
            "Error rate: 0.572 vs 0.564\n",
            "187/187 - 45s - loss: 18.1841 - binary_acc: 0.9461 - val_loss: 23.4214 - val_binary_acc: 0.9239 - 45s/epoch - 242ms/step\n",
            "Epoch 111/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.527 vs 0.559\n",
            "Error rate: 0.595 vs 0.564\n",
            "187/187 - 45s - loss: 18.1679 - binary_acc: 0.9463 - val_loss: 23.8533 - val_binary_acc: 0.9221 - 45s/epoch - 242ms/step\n",
            "Epoch 112/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.534 vs 0.559\n",
            "Error rate: 0.590 vs 0.564\n",
            "187/187 - 45s - loss: 18.2965 - binary_acc: 0.9456 - val_loss: 23.2339 - val_binary_acc: 0.9248 - 45s/epoch - 242ms/step\n",
            "Epoch 113/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.545 vs 0.559\n",
            "Error rate: 0.581 vs 0.564\n",
            "187/187 - 46s - loss: 18.0338 - binary_acc: 0.9468 - val_loss: 22.7879 - val_binary_acc: 0.9250 - 46s/epoch - 245ms/step\n",
            "Epoch 114/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.536 vs 0.559\n",
            "Error rate: 0.591 vs 0.564\n",
            "187/187 - 45s - loss: 18.1075 - binary_acc: 0.9463 - val_loss: 23.2885 - val_binary_acc: 0.9253 - 45s/epoch - 243ms/step\n",
            "Epoch 115/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.559\n",
            "Error rate: 0.567 vs 0.564\n",
            "187/187 - 49s - loss: 18.1041 - binary_acc: 0.9466 - val_loss: 23.3672 - val_binary_acc: 0.9236 - 49s/epoch - 263ms/step\n",
            "Epoch 116/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.562 vs 0.562\n",
            "Error rate: 0.563 vs 0.563\n",
            "187/187 - 49s - loss: 18.1662 - binary_acc: 0.9461 - val_loss: 22.8997 - val_binary_acc: 0.9250 - 49s/epoch - 265ms/step\n",
            "Epoch 117/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.539 vs 0.562\n",
            "Error rate: 0.583 vs 0.563\n",
            "187/187 - 51s - loss: 18.1353 - binary_acc: 0.9462 - val_loss: 23.3303 - val_binary_acc: 0.9245 - 51s/epoch - 270ms/step\n",
            "Epoch 118/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.549 vs 0.562\n",
            "Error rate: 0.575 vs 0.563\n",
            "187/187 - 45s - loss: 18.1405 - binary_acc: 0.9462 - val_loss: 22.9568 - val_binary_acc: 0.9246 - 45s/epoch - 239ms/step\n",
            "Epoch 119/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.543 vs 0.562\n",
            "Error rate: 0.582 vs 0.563\n",
            "187/187 - 47s - loss: 18.1142 - binary_acc: 0.9459 - val_loss: 23.4171 - val_binary_acc: 0.9236 - 47s/epoch - 252ms/step\n",
            "Epoch 120/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.535 vs 0.562\n",
            "Error rate: 0.589 vs 0.563\n",
            "187/187 - 45s - loss: 18.1100 - binary_acc: 0.9463 - val_loss: 23.4247 - val_binary_acc: 0.9245 - 45s/epoch - 243ms/step\n",
            "Epoch 121/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.531 vs 0.562\n",
            "Error rate: 0.592 vs 0.563\n",
            "187/187 - 46s - loss: 18.1208 - binary_acc: 0.9461 - val_loss: 23.6171 - val_binary_acc: 0.9224 - 46s/epoch - 247ms/step\n",
            "Epoch 122/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.549 vs 0.562\n",
            "Error rate: 0.575 vs 0.563\n",
            "187/187 - 46s - loss: 18.0012 - binary_acc: 0.9468 - val_loss: 22.8915 - val_binary_acc: 0.9247 - 46s/epoch - 247ms/step\n",
            "Epoch 123/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.549 vs 0.562\n",
            "Error rate: 0.577 vs 0.563\n",
            "187/187 - 46s - loss: 18.0452 - binary_acc: 0.9461 - val_loss: 23.0163 - val_binary_acc: 0.9258 - 46s/epoch - 248ms/step\n",
            "Epoch 124/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.537 vs 0.562\n",
            "Error rate: 0.589 vs 0.563\n",
            "187/187 - 48s - loss: 18.1015 - binary_acc: 0.9464 - val_loss: 23.2994 - val_binary_acc: 0.9249 - 48s/epoch - 255ms/step\n",
            "Epoch 125/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.533 vs 0.562\n",
            "Error rate: 0.588 vs 0.563\n",
            "187/187 - 47s - loss: 18.0200 - binary_acc: 0.9466 - val_loss: 23.3717 - val_binary_acc: 0.9234 - 47s/epoch - 253ms/step\n",
            "Epoch 126/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.534 vs 0.562\n",
            "Error rate: 0.589 vs 0.563\n",
            "187/187 - 45s - loss: 18.0327 - binary_acc: 0.9465 - val_loss: 23.2381 - val_binary_acc: 0.9243 - 45s/epoch - 242ms/step\n",
            "Epoch 127/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.540 vs 0.562\n",
            "Error rate: 0.579 vs 0.563\n",
            "187/187 - 46s - loss: 17.9845 - binary_acc: 0.9468 - val_loss: 23.7708 - val_binary_acc: 0.9220 - 46s/epoch - 248ms/step\n",
            "Epoch 128/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.534 vs 0.562\n",
            "Error rate: 0.587 vs 0.563\n",
            "187/187 - 46s - loss: 17.9870 - binary_acc: 0.9466 - val_loss: 23.5257 - val_binary_acc: 0.9239 - 46s/epoch - 247ms/step\n",
            "Epoch 129/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.562\n",
            "Error rate: 0.566 vs 0.563\n",
            "187/187 - 49s - loss: 17.9389 - binary_acc: 0.9469 - val_loss: 22.9208 - val_binary_acc: 0.9250 - 49s/epoch - 261ms/step\n",
            "Epoch 130/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.574 vs 0.574\n",
            "Error rate: 0.554 vs 0.554\n",
            "187/187 - 49s - loss: 17.9771 - binary_acc: 0.9468 - val_loss: 22.2184 - val_binary_acc: 0.9281 - 49s/epoch - 264ms/step\n",
            "Epoch 131/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.570 vs 0.574\n",
            "Error rate: 0.558 vs 0.554\n",
            "187/187 - 48s - loss: 17.9729 - binary_acc: 0.9467 - val_loss: 22.5465 - val_binary_acc: 0.9272 - 48s/epoch - 257ms/step\n",
            "Epoch 132/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.544 vs 0.574\n",
            "Error rate: 0.581 vs 0.554\n",
            "187/187 - 49s - loss: 18.0506 - binary_acc: 0.9465 - val_loss: 23.5143 - val_binary_acc: 0.9238 - 49s/epoch - 263ms/step\n",
            "Epoch 133/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.565 vs 0.574\n",
            "Error rate: 0.560 vs 0.554\n",
            "187/187 - 45s - loss: 17.9548 - binary_acc: 0.9469 - val_loss: 22.6793 - val_binary_acc: 0.9261 - 45s/epoch - 243ms/step\n",
            "Epoch 134/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.574\n",
            "Error rate: 0.573 vs 0.554\n",
            "187/187 - 46s - loss: 17.9772 - binary_acc: 0.9467 - val_loss: 22.4134 - val_binary_acc: 0.9276 - 46s/epoch - 245ms/step\n",
            "Epoch 135/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.545 vs 0.574\n",
            "Error rate: 0.579 vs 0.554\n",
            "187/187 - 45s - loss: 17.9432 - binary_acc: 0.9468 - val_loss: 23.1670 - val_binary_acc: 0.9253 - 45s/epoch - 242ms/step\n",
            "Epoch 136/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.574\n",
            "Error rate: 0.568 vs 0.554\n",
            "187/187 - 46s - loss: 17.9797 - binary_acc: 0.9467 - val_loss: 22.7057 - val_binary_acc: 0.9262 - 46s/epoch - 247ms/step\n",
            "Epoch 137/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.554 vs 0.574\n",
            "Error rate: 0.567 vs 0.554\n",
            "187/187 - 46s - loss: 17.8974 - binary_acc: 0.9472 - val_loss: 23.4840 - val_binary_acc: 0.9230 - 46s/epoch - 247ms/step\n",
            "Epoch 138/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.563 vs 0.574\n",
            "Error rate: 0.561 vs 0.554\n",
            "187/187 - 48s - loss: 17.8952 - binary_acc: 0.9472 - val_loss: 23.2105 - val_binary_acc: 0.9241 - 48s/epoch - 257ms/step\n",
            "Epoch 139/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.561 vs 0.574\n",
            "Error rate: 0.563 vs 0.554\n",
            "187/187 - 45s - loss: 17.9875 - binary_acc: 0.9469 - val_loss: 23.1335 - val_binary_acc: 0.9250 - 45s/epoch - 242ms/step\n",
            "Epoch 140/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.543 vs 0.574\n",
            "Error rate: 0.584 vs 0.554\n",
            "187/187 - 47s - loss: 17.8287 - binary_acc: 0.9473 - val_loss: 23.0990 - val_binary_acc: 0.9250 - 47s/epoch - 249ms/step\n",
            "Epoch 141/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.550 vs 0.574\n",
            "Error rate: 0.578 vs 0.554\n",
            "187/187 - 46s - loss: 17.8588 - binary_acc: 0.9469 - val_loss: 22.7363 - val_binary_acc: 0.9258 - 46s/epoch - 243ms/step\n",
            "Epoch 142/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.561 vs 0.574\n",
            "Error rate: 0.563 vs 0.554\n",
            "187/187 - 46s - loss: 17.8399 - binary_acc: 0.9472 - val_loss: 23.0258 - val_binary_acc: 0.9242 - 46s/epoch - 244ms/step\n",
            "Epoch 143/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.554 vs 0.574\n",
            "Error rate: 0.570 vs 0.554\n",
            "187/187 - 46s - loss: 17.8417 - binary_acc: 0.9473 - val_loss: 23.0016 - val_binary_acc: 0.9262 - 46s/epoch - 244ms/step\n",
            "Epoch 144/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.546 vs 0.574\n",
            "Error rate: 0.579 vs 0.554\n",
            "187/187 - 46s - loss: 17.8706 - binary_acc: 0.9472 - val_loss: 23.0571 - val_binary_acc: 0.9252 - 46s/epoch - 248ms/step\n",
            "Epoch 145/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.570 vs 0.574\n",
            "Error rate: 0.556 vs 0.554\n",
            "187/187 - 47s - loss: 17.7760 - binary_acc: 0.9473 - val_loss: 22.8700 - val_binary_acc: 0.9250 - 47s/epoch - 251ms/step\n",
            "Epoch 146/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.556 vs 0.574\n",
            "Error rate: 0.574 vs 0.554\n",
            "187/187 - 46s - loss: 17.8628 - binary_acc: 0.9471 - val_loss: 22.5881 - val_binary_acc: 0.9274 - 46s/epoch - 247ms/step\n",
            "Epoch 147/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.557 vs 0.574\n",
            "Error rate: 0.567 vs 0.554\n",
            "187/187 - 47s - loss: 17.7160 - binary_acc: 0.9477 - val_loss: 22.9904 - val_binary_acc: 0.9243 - 47s/epoch - 249ms/step\n",
            "Epoch 148/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.550 vs 0.574\n",
            "Error rate: 0.578 vs 0.554\n",
            "187/187 - 46s - loss: 17.7594 - binary_acc: 0.9474 - val_loss: 22.6286 - val_binary_acc: 0.9266 - 46s/epoch - 247ms/step\n",
            "Epoch 149/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.558 vs 0.574\n",
            "Error rate: 0.569 vs 0.554\n",
            "187/187 - 47s - loss: 17.7006 - binary_acc: 0.9477 - val_loss: 22.4008 - val_binary_acc: 0.9285 - 47s/epoch - 249ms/step\n",
            "Epoch 150/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.533 vs 0.574\n",
            "Error rate: 0.591 vs 0.554\n",
            "187/187 - 46s - loss: 17.6657 - binary_acc: 0.9480 - val_loss: 23.5664 - val_binary_acc: 0.9233 - 46s/epoch - 245ms/step\n",
            "Epoch 151/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.546 vs 0.574\n",
            "Error rate: 0.577 vs 0.554\n",
            "187/187 - 47s - loss: 17.7491 - binary_acc: 0.9476 - val_loss: 22.9153 - val_binary_acc: 0.9252 - 47s/epoch - 249ms/step\n",
            "Epoch 152/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.551 vs 0.574\n",
            "Error rate: 0.575 vs 0.554\n",
            "187/187 - 47s - loss: 17.7477 - binary_acc: 0.9476 - val_loss: 22.7730 - val_binary_acc: 0.9265 - 47s/epoch - 249ms/step\n",
            "Epoch 153/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.541 vs 0.574\n",
            "Error rate: 0.581 vs 0.554\n",
            "187/187 - 47s - loss: 17.8573 - binary_acc: 0.9469 - val_loss: 23.3237 - val_binary_acc: 0.9246 - 47s/epoch - 250ms/step\n",
            "Epoch 154/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.563 vs 0.574\n",
            "Error rate: 0.563 vs 0.554\n",
            "187/187 - 46s - loss: 17.8035 - binary_acc: 0.9477 - val_loss: 22.7709 - val_binary_acc: 0.9262 - 46s/epoch - 246ms/step\n",
            "Epoch 155/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.560 vs 0.574\n",
            "Error rate: 0.562 vs 0.554\n",
            "187/187 - 47s - loss: 17.7889 - binary_acc: 0.9475 - val_loss: 22.8680 - val_binary_acc: 0.9259 - 47s/epoch - 252ms/step\n",
            "Epoch 156/1000\n"
          ]
        }
      ],
      "source": [
        "# coh_loss = 0.5\n",
        "model.fit(training_generator, validation_data=validation_generator, epochs=1000, callbacks=[MyCustomCallback_44()], verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NawzhAToS8o_",
        "outputId": "3d1779e4-2533-4013-9915-60a141e0780d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "63/63 [==============================] - 3s 32ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 84s - loss: 83.9003 - binary_acc: 0.9134 - val_loss: 105.1496 - val_binary_acc: 0.9212 - 84s/epoch - 448ms/step\n",
            "Epoch 2/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 48s - loss: 61.6494 - binary_acc: 0.9197 - val_loss: 74.1958 - val_binary_acc: 0.9212 - 48s/epoch - 257ms/step\n",
            "Epoch 3/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "187/187 - 45s - loss: 48.5595 - binary_acc: 0.9199 - val_loss: 50.2309 - val_binary_acc: 0.9213 - 45s/epoch - 242ms/step\n",
            "Epoch 4/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.001 vs 0.001\n",
            "Error rate: 0.999 vs 0.999\n",
            "187/187 - 49s - loss: 40.7893 - binary_acc: 0.9206 - val_loss: 40.4519 - val_binary_acc: 0.9214 - 49s/epoch - 260ms/step\n",
            "Epoch 5/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.150 vs 0.150\n",
            "Error rate: 0.916 vs 0.916\n",
            "187/187 - 49s - loss: 35.9382 - binary_acc: 0.9216 - val_loss: 35.4049 - val_binary_acc: 0.9195 - 49s/epoch - 263ms/step\n",
            "Epoch 6/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.198 vs 0.198\n",
            "Error rate: 0.886 vs 0.886\n",
            "187/187 - 50s - loss: 32.6393 - binary_acc: 0.9222 - val_loss: 32.4173 - val_binary_acc: 0.9210 - 50s/epoch - 268ms/step\n",
            "Epoch 7/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.154 vs 0.198\n",
            "Error rate: 0.917 vs 0.886\n",
            "187/187 - 45s - loss: 30.1923 - binary_acc: 0.9230 - val_loss: 29.7009 - val_binary_acc: 0.9223 - 45s/epoch - 243ms/step\n",
            "Epoch 8/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.254 vs 0.254\n",
            "Error rate: 0.846 vs 0.846\n",
            "187/187 - 51s - loss: 28.3879 - binary_acc: 0.9238 - val_loss: 28.9685 - val_binary_acc: 0.9213 - 51s/epoch - 273ms/step\n",
            "Epoch 9/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.254 vs 0.254\n",
            "Error rate: 0.849 vs 0.846\n",
            "187/187 - 47s - loss: 27.0965 - binary_acc: 0.9247 - val_loss: 27.3591 - val_binary_acc: 0.9226 - 47s/epoch - 252ms/step\n",
            "Epoch 10/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.312 vs 0.312\n",
            "Error rate: 0.793 vs 0.793\n",
            "187/187 - 51s - loss: 26.0551 - binary_acc: 0.9257 - val_loss: 27.7452 - val_binary_acc: 0.9177 - 51s/epoch - 271ms/step\n",
            "Epoch 11/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.333 vs 0.333\n",
            "Error rate: 0.781 vs 0.781\n",
            "187/187 - 52s - loss: 25.3255 - binary_acc: 0.9261 - val_loss: 26.9076 - val_binary_acc: 0.9203 - 52s/epoch - 276ms/step\n",
            "Epoch 12/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.357 vs 0.357\n",
            "Error rate: 0.761 vs 0.761\n",
            "187/187 - 51s - loss: 24.7108 - binary_acc: 0.9269 - val_loss: 26.4622 - val_binary_acc: 0.9193 - 51s/epoch - 275ms/step\n",
            "Epoch 13/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.376 vs 0.376\n",
            "Error rate: 0.737 vs 0.737\n",
            "187/187 - 52s - loss: 24.1140 - binary_acc: 0.9279 - val_loss: 26.6926 - val_binary_acc: 0.9167 - 52s/epoch - 277ms/step\n",
            "Epoch 14/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.342 vs 0.376\n",
            "Error rate: 0.776 vs 0.737\n",
            "187/187 - 46s - loss: 23.5232 - binary_acc: 0.9295 - val_loss: 25.3528 - val_binary_acc: 0.9218 - 46s/epoch - 248ms/step\n",
            "Epoch 15/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.387 vs 0.387\n",
            "Error rate: 0.731 vs 0.731\n",
            "187/187 - 52s - loss: 23.1418 - binary_acc: 0.9297 - val_loss: 25.4612 - val_binary_acc: 0.9193 - 52s/epoch - 275ms/step\n",
            "Epoch 16/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.399 vs 0.399\n",
            "Error rate: 0.724 vs 0.724\n",
            "187/187 - 51s - loss: 22.9336 - binary_acc: 0.9304 - val_loss: 25.1171 - val_binary_acc: 0.9218 - 51s/epoch - 274ms/step\n",
            "Epoch 17/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.439 vs 0.439\n",
            "Error rate: 0.683 vs 0.683\n",
            "187/187 - 51s - loss: 22.5306 - binary_acc: 0.9314 - val_loss: 25.5452 - val_binary_acc: 0.9197 - 51s/epoch - 272ms/step\n",
            "Epoch 18/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.441 vs 0.441\n",
            "Error rate: 0.685 vs 0.683\n",
            "187/187 - 48s - loss: 22.4437 - binary_acc: 0.9321 - val_loss: 24.7003 - val_binary_acc: 0.9234 - 48s/epoch - 259ms/step\n",
            "Epoch 19/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.436 vs 0.441\n",
            "Error rate: 0.689 vs 0.683\n",
            "187/187 - 46s - loss: 22.0794 - binary_acc: 0.9332 - val_loss: 24.6774 - val_binary_acc: 0.9219 - 46s/epoch - 246ms/step\n",
            "Epoch 20/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.435 vs 0.441\n",
            "Error rate: 0.683 vs 0.683\n",
            "187/187 - 53s - loss: 21.8753 - binary_acc: 0.9337 - val_loss: 25.4779 - val_binary_acc: 0.9178 - 53s/epoch - 281ms/step\n",
            "Epoch 21/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.501 vs 0.501\n",
            "Error rate: 0.628 vs 0.628\n",
            "187/187 - 51s - loss: 21.6128 - binary_acc: 0.9348 - val_loss: 23.8706 - val_binary_acc: 0.9254 - 51s/epoch - 275ms/step\n",
            "Epoch 22/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.495 vs 0.501\n",
            "Error rate: 0.631 vs 0.628\n",
            "187/187 - 47s - loss: 21.5054 - binary_acc: 0.9352 - val_loss: 24.4446 - val_binary_acc: 0.9232 - 47s/epoch - 250ms/step\n",
            "Epoch 23/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.492 vs 0.501\n",
            "Error rate: 0.634 vs 0.628\n",
            "187/187 - 46s - loss: 21.2816 - binary_acc: 0.9359 - val_loss: 24.2546 - val_binary_acc: 0.9227 - 46s/epoch - 248ms/step\n",
            "Epoch 24/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.431 vs 0.501\n",
            "Error rate: 0.692 vs 0.628\n",
            "187/187 - 50s - loss: 21.3011 - binary_acc: 0.9358 - val_loss: 24.8255 - val_binary_acc: 0.9212 - 50s/epoch - 266ms/step\n",
            "Epoch 25/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.469 vs 0.501\n",
            "Error rate: 0.655 vs 0.628\n",
            "187/187 - 46s - loss: 21.0309 - binary_acc: 0.9363 - val_loss: 24.6630 - val_binary_acc: 0.9208 - 46s/epoch - 244ms/step\n",
            "Epoch 26/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.510 vs 0.510\n",
            "Error rate: 0.617 vs 0.617\n",
            "187/187 - 51s - loss: 20.9967 - binary_acc: 0.9367 - val_loss: 24.1067 - val_binary_acc: 0.9234 - 51s/epoch - 273ms/step\n",
            "Epoch 27/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.501 vs 0.510\n",
            "Error rate: 0.628 vs 0.617\n",
            "187/187 - 46s - loss: 20.8397 - binary_acc: 0.9373 - val_loss: 23.6521 - val_binary_acc: 0.9246 - 46s/epoch - 245ms/step\n",
            "Epoch 28/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.500 vs 0.510\n",
            "Error rate: 0.629 vs 0.617\n",
            "187/187 - 48s - loss: 20.6898 - binary_acc: 0.9375 - val_loss: 23.5828 - val_binary_acc: 0.9250 - 48s/epoch - 255ms/step\n",
            "Epoch 29/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.499 vs 0.510\n",
            "Error rate: 0.627 vs 0.617\n",
            "187/187 - 47s - loss: 20.6889 - binary_acc: 0.9376 - val_loss: 24.1736 - val_binary_acc: 0.9227 - 47s/epoch - 250ms/step\n",
            "Epoch 30/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.488 vs 0.510\n",
            "Error rate: 0.637 vs 0.617\n",
            "187/187 - 46s - loss: 20.5670 - binary_acc: 0.9383 - val_loss: 25.0447 - val_binary_acc: 0.9206 - 46s/epoch - 245ms/step\n",
            "Epoch 31/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.499 vs 0.510\n",
            "Error rate: 0.631 vs 0.617\n",
            "187/187 - 51s - loss: 20.5803 - binary_acc: 0.9382 - val_loss: 23.5008 - val_binary_acc: 0.9263 - 51s/epoch - 270ms/step\n",
            "Epoch 32/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.509 vs 0.510\n",
            "Error rate: 0.615 vs 0.615\n",
            "187/187 - 49s - loss: 20.3453 - binary_acc: 0.9391 - val_loss: 23.8059 - val_binary_acc: 0.9236 - 49s/epoch - 262ms/step\n",
            "Epoch 33/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.508 vs 0.510\n",
            "Error rate: 0.620 vs 0.615\n",
            "187/187 - 46s - loss: 20.3059 - binary_acc: 0.9389 - val_loss: 23.6373 - val_binary_acc: 0.9253 - 46s/epoch - 246ms/step\n",
            "Epoch 34/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.520 vs 0.520\n",
            "Error rate: 0.607 vs 0.607\n",
            "187/187 - 50s - loss: 20.2407 - binary_acc: 0.9397 - val_loss: 23.7494 - val_binary_acc: 0.9236 - 50s/epoch - 266ms/step\n",
            "Epoch 35/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.521 vs 0.521\n",
            "Error rate: 0.609 vs 0.607\n",
            "187/187 - 49s - loss: 20.2539 - binary_acc: 0.9394 - val_loss: 23.4671 - val_binary_acc: 0.9253 - 49s/epoch - 260ms/step\n",
            "Epoch 36/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.511 vs 0.521\n",
            "Error rate: 0.619 vs 0.607\n",
            "187/187 - 48s - loss: 20.1303 - binary_acc: 0.9399 - val_loss: 23.2211 - val_binary_acc: 0.9262 - 48s/epoch - 255ms/step\n",
            "Epoch 37/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.515 vs 0.521\n",
            "Error rate: 0.614 vs 0.607\n",
            "187/187 - 49s - loss: 19.9999 - binary_acc: 0.9404 - val_loss: 23.3883 - val_binary_acc: 0.9251 - 49s/epoch - 259ms/step\n",
            "Epoch 38/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.531 vs 0.531\n",
            "Error rate: 0.597 vs 0.597\n",
            "187/187 - 50s - loss: 19.9169 - binary_acc: 0.9403 - val_loss: 23.6488 - val_binary_acc: 0.9242 - 50s/epoch - 269ms/step\n",
            "Epoch 39/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.503 vs 0.531\n",
            "Error rate: 0.622 vs 0.597\n",
            "187/187 - 51s - loss: 19.8638 - binary_acc: 0.9408 - val_loss: 24.0562 - val_binary_acc: 0.9235 - 51s/epoch - 275ms/step\n",
            "Epoch 40/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.509 vs 0.531\n",
            "Error rate: 0.619 vs 0.597\n",
            "187/187 - 48s - loss: 19.7610 - binary_acc: 0.9410 - val_loss: 23.8477 - val_binary_acc: 0.9232 - 48s/epoch - 257ms/step\n",
            "Epoch 41/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.498 vs 0.531\n",
            "Error rate: 0.627 vs 0.597\n",
            "187/187 - 52s - loss: 19.7791 - binary_acc: 0.9410 - val_loss: 24.3552 - val_binary_acc: 0.9216 - 52s/epoch - 280ms/step\n",
            "Epoch 42/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.519 vs 0.531\n",
            "Error rate: 0.610 vs 0.597\n",
            "187/187 - 48s - loss: 19.8258 - binary_acc: 0.9410 - val_loss: 23.2981 - val_binary_acc: 0.9250 - 48s/epoch - 259ms/step\n",
            "Epoch 43/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.507 vs 0.531\n",
            "Error rate: 0.617 vs 0.597\n",
            "187/187 - 50s - loss: 19.7025 - binary_acc: 0.9411 - val_loss: 23.7244 - val_binary_acc: 0.9234 - 50s/epoch - 269ms/step\n",
            "Epoch 44/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.528 vs 0.531\n",
            "Error rate: 0.604 vs 0.597\n",
            "187/187 - 50s - loss: 19.5799 - binary_acc: 0.9414 - val_loss: 23.1663 - val_binary_acc: 0.9267 - 50s/epoch - 265ms/step\n",
            "Epoch 45/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.530 vs 0.531\n",
            "Error rate: 0.596 vs 0.596\n",
            "187/187 - 52s - loss: 19.6697 - binary_acc: 0.9416 - val_loss: 23.6347 - val_binary_acc: 0.9243 - 52s/epoch - 276ms/step\n",
            "Epoch 46/1000\n",
            "63/63 [==============================] - 2s 28ms/step\n",
            "F-measure: 0.531 vs 0.531\n",
            "Error rate: 0.599 vs 0.596\n",
            "187/187 - 51s - loss: 19.5815 - binary_acc: 0.9416 - val_loss: 23.2353 - val_binary_acc: 0.9254 - 51s/epoch - 275ms/step\n",
            "Epoch 47/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.525 vs 0.531\n",
            "Error rate: 0.602 vs 0.596\n",
            "187/187 - 48s - loss: 19.3571 - binary_acc: 0.9423 - val_loss: 23.5776 - val_binary_acc: 0.9248 - 48s/epoch - 257ms/step\n",
            "Epoch 48/1000\n",
            "63/63 [==============================] - 2s 28ms/step\n",
            "F-measure: 0.521 vs 0.531\n",
            "Error rate: 0.603 vs 0.596\n",
            "187/187 - 49s - loss: 19.3831 - binary_acc: 0.9422 - val_loss: 24.1081 - val_binary_acc: 0.9230 - 49s/epoch - 260ms/step\n",
            "Epoch 49/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.507 vs 0.531\n",
            "Error rate: 0.615 vs 0.596\n",
            "187/187 - 47s - loss: 19.5072 - binary_acc: 0.9417 - val_loss: 24.0079 - val_binary_acc: 0.9233 - 47s/epoch - 250ms/step\n",
            "Epoch 50/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.512 vs 0.531\n",
            "Error rate: 0.612 vs 0.596\n",
            "187/187 - 54s - loss: 19.2924 - binary_acc: 0.9424 - val_loss: 24.0172 - val_binary_acc: 0.9226 - 54s/epoch - 288ms/step\n",
            "Epoch 51/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.516 vs 0.531\n",
            "Error rate: 0.606 vs 0.596\n",
            "187/187 - 51s - loss: 19.2629 - binary_acc: 0.9425 - val_loss: 23.8541 - val_binary_acc: 0.9237 - 51s/epoch - 275ms/step\n",
            "Epoch 52/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.510 vs 0.531\n",
            "Error rate: 0.613 vs 0.596\n",
            "187/187 - 48s - loss: 19.2524 - binary_acc: 0.9425 - val_loss: 24.0835 - val_binary_acc: 0.9223 - 48s/epoch - 256ms/step\n",
            "Epoch 53/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.535 vs 0.535\n",
            "Error rate: 0.590 vs 0.590\n",
            "187/187 - 53s - loss: 19.2273 - binary_acc: 0.9425 - val_loss: 23.1782 - val_binary_acc: 0.9257 - 53s/epoch - 282ms/step\n",
            "Epoch 54/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.513 vs 0.535\n",
            "Error rate: 0.612 vs 0.590\n",
            "187/187 - 48s - loss: 19.1265 - binary_acc: 0.9428 - val_loss: 23.7247 - val_binary_acc: 0.9231 - 48s/epoch - 256ms/step\n",
            "Epoch 55/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.531 vs 0.535\n",
            "Error rate: 0.598 vs 0.590\n",
            "187/187 - 51s - loss: 19.1799 - binary_acc: 0.9426 - val_loss: 23.1587 - val_binary_acc: 0.9256 - 51s/epoch - 273ms/step\n",
            "Epoch 56/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.529 vs 0.535\n",
            "Error rate: 0.599 vs 0.590\n",
            "187/187 - 48s - loss: 19.0962 - binary_acc: 0.9427 - val_loss: 23.2659 - val_binary_acc: 0.9250 - 48s/epoch - 254ms/step\n",
            "Epoch 57/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.523 vs 0.535\n",
            "Error rate: 0.601 vs 0.590\n",
            "187/187 - 48s - loss: 19.1035 - binary_acc: 0.9432 - val_loss: 23.7441 - val_binary_acc: 0.9233 - 48s/epoch - 257ms/step\n",
            "Epoch 58/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.556\n",
            "Error rate: 0.573 vs 0.573\n",
            "187/187 - 52s - loss: 19.1248 - binary_acc: 0.9429 - val_loss: 23.2382 - val_binary_acc: 0.9249 - 52s/epoch - 280ms/step\n",
            "Epoch 59/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.536 vs 0.556\n",
            "Error rate: 0.590 vs 0.573\n",
            "187/187 - 51s - loss: 19.1336 - binary_acc: 0.9431 - val_loss: 23.4049 - val_binary_acc: 0.9251 - 51s/epoch - 274ms/step\n",
            "Epoch 60/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.552 vs 0.556\n",
            "Error rate: 0.575 vs 0.573\n",
            "187/187 - 48s - loss: 18.9951 - binary_acc: 0.9434 - val_loss: 22.8554 - val_binary_acc: 0.9258 - 48s/epoch - 255ms/step\n",
            "Epoch 61/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.559 vs 0.559\n",
            "Error rate: 0.567 vs 0.567\n",
            "187/187 - 53s - loss: 18.9478 - binary_acc: 0.9436 - val_loss: 22.9680 - val_binary_acc: 0.9267 - 53s/epoch - 282ms/step\n",
            "Epoch 62/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.525 vs 0.559\n",
            "Error rate: 0.602 vs 0.567\n",
            "187/187 - 48s - loss: 18.9477 - binary_acc: 0.9437 - val_loss: 24.1147 - val_binary_acc: 0.9216 - 48s/epoch - 255ms/step\n",
            "Epoch 63/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.537 vs 0.559\n",
            "Error rate: 0.591 vs 0.567\n",
            "187/187 - 48s - loss: 18.9352 - binary_acc: 0.9436 - val_loss: 23.2060 - val_binary_acc: 0.9251 - 48s/epoch - 257ms/step\n",
            "Epoch 64/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.524 vs 0.559\n",
            "Error rate: 0.605 vs 0.567\n",
            "187/187 - 50s - loss: 18.8357 - binary_acc: 0.9441 - val_loss: 23.1434 - val_binary_acc: 0.9265 - 50s/epoch - 265ms/step\n",
            "Epoch 65/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.528 vs 0.559\n",
            "Error rate: 0.600 vs 0.567\n",
            "187/187 - 48s - loss: 18.7018 - binary_acc: 0.9444 - val_loss: 22.9876 - val_binary_acc: 0.9269 - 48s/epoch - 256ms/step\n",
            "Epoch 66/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.523 vs 0.559\n",
            "Error rate: 0.606 vs 0.567\n",
            "187/187 - 48s - loss: 18.8184 - binary_acc: 0.9438 - val_loss: 23.1620 - val_binary_acc: 0.9247 - 48s/epoch - 258ms/step\n",
            "Epoch 67/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.563 vs 0.563\n",
            "Error rate: 0.567 vs 0.567\n",
            "187/187 - 50s - loss: 18.7844 - binary_acc: 0.9438 - val_loss: 22.5749 - val_binary_acc: 0.9285 - 50s/epoch - 268ms/step\n",
            "Epoch 68/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.537 vs 0.563\n",
            "Error rate: 0.588 vs 0.567\n",
            "187/187 - 49s - loss: 18.7674 - binary_acc: 0.9440 - val_loss: 23.5514 - val_binary_acc: 0.9244 - 49s/epoch - 261ms/step\n",
            "Epoch 69/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.545 vs 0.563\n",
            "Error rate: 0.581 vs 0.567\n",
            "187/187 - 50s - loss: 18.7755 - binary_acc: 0.9441 - val_loss: 23.3365 - val_binary_acc: 0.9252 - 50s/epoch - 265ms/step\n",
            "Epoch 70/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.563\n",
            "Error rate: 0.575 vs 0.567\n",
            "187/187 - 48s - loss: 18.8492 - binary_acc: 0.9437 - val_loss: 23.2250 - val_binary_acc: 0.9255 - 48s/epoch - 257ms/step\n",
            "Epoch 71/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.538 vs 0.563\n",
            "Error rate: 0.585 vs 0.567\n",
            "187/187 - 48s - loss: 18.6882 - binary_acc: 0.9445 - val_loss: 23.4921 - val_binary_acc: 0.9238 - 48s/epoch - 257ms/step\n",
            "Epoch 72/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.530 vs 0.563\n",
            "Error rate: 0.592 vs 0.567\n",
            "187/187 - 49s - loss: 18.6836 - binary_acc: 0.9443 - val_loss: 23.1946 - val_binary_acc: 0.9249 - 49s/epoch - 262ms/step\n",
            "Epoch 73/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.562 vs 0.563\n",
            "Error rate: 0.568 vs 0.567\n",
            "187/187 - 51s - loss: 18.6371 - binary_acc: 0.9446 - val_loss: 22.9081 - val_binary_acc: 0.9270 - 51s/epoch - 272ms/step\n",
            "Epoch 74/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.549 vs 0.563\n",
            "Error rate: 0.576 vs 0.567\n",
            "187/187 - 48s - loss: 18.7284 - binary_acc: 0.9443 - val_loss: 23.4676 - val_binary_acc: 0.9234 - 48s/epoch - 257ms/step\n",
            "Epoch 75/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.556 vs 0.563\n",
            "Error rate: 0.574 vs 0.567\n",
            "187/187 - 48s - loss: 18.5677 - binary_acc: 0.9448 - val_loss: 22.4528 - val_binary_acc: 0.9289 - 48s/epoch - 255ms/step\n",
            "Epoch 76/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.528 vs 0.563\n",
            "Error rate: 0.599 vs 0.567\n",
            "187/187 - 50s - loss: 18.5522 - binary_acc: 0.9449 - val_loss: 23.2382 - val_binary_acc: 0.9255 - 50s/epoch - 267ms/step\n",
            "Epoch 77/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.534 vs 0.563\n",
            "Error rate: 0.593 vs 0.567\n",
            "187/187 - 48s - loss: 18.5485 - binary_acc: 0.9449 - val_loss: 23.1873 - val_binary_acc: 0.9248 - 48s/epoch - 254ms/step\n",
            "Epoch 78/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.541 vs 0.563\n",
            "Error rate: 0.587 vs 0.567\n",
            "187/187 - 48s - loss: 18.5245 - binary_acc: 0.9448 - val_loss: 22.8015 - val_binary_acc: 0.9267 - 48s/epoch - 254ms/step\n",
            "Epoch 79/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.517 vs 0.563\n",
            "Error rate: 0.602 vs 0.567\n",
            "187/187 - 48s - loss: 18.5464 - binary_acc: 0.9446 - val_loss: 23.9961 - val_binary_acc: 0.9223 - 48s/epoch - 256ms/step\n",
            "Epoch 80/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.563\n",
            "Error rate: 0.576 vs 0.567\n",
            "187/187 - 47s - loss: 18.5647 - binary_acc: 0.9447 - val_loss: 23.2780 - val_binary_acc: 0.9251 - 47s/epoch - 253ms/step\n",
            "Epoch 81/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.537 vs 0.563\n",
            "Error rate: 0.588 vs 0.567\n",
            "187/187 - 46s - loss: 18.5625 - binary_acc: 0.9445 - val_loss: 23.4045 - val_binary_acc: 0.9236 - 46s/epoch - 247ms/step\n",
            "Epoch 82/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.563\n",
            "Error rate: 0.575 vs 0.567\n",
            "187/187 - 51s - loss: 18.4440 - binary_acc: 0.9450 - val_loss: 22.9154 - val_binary_acc: 0.9251 - 51s/epoch - 272ms/step\n",
            "Epoch 83/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.518 vs 0.563\n",
            "Error rate: 0.610 vs 0.567\n",
            "187/187 - 48s - loss: 18.5020 - binary_acc: 0.9448 - val_loss: 23.2543 - val_binary_acc: 0.9249 - 48s/epoch - 254ms/step\n",
            "Epoch 84/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.527 vs 0.563\n",
            "Error rate: 0.596 vs 0.567\n",
            "187/187 - 47s - loss: 18.4296 - binary_acc: 0.9452 - val_loss: 24.0992 - val_binary_acc: 0.9203 - 47s/epoch - 249ms/step\n",
            "Epoch 85/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.536 vs 0.563\n",
            "Error rate: 0.588 vs 0.567\n",
            "187/187 - 48s - loss: 18.4151 - binary_acc: 0.9453 - val_loss: 23.1810 - val_binary_acc: 0.9247 - 48s/epoch - 255ms/step\n",
            "Epoch 86/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.544 vs 0.563\n",
            "Error rate: 0.581 vs 0.567\n",
            "187/187 - 50s - loss: 18.3315 - binary_acc: 0.9457 - val_loss: 22.8570 - val_binary_acc: 0.9264 - 50s/epoch - 266ms/step\n",
            "Epoch 87/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.532 vs 0.563\n",
            "Error rate: 0.593 vs 0.567\n",
            "187/187 - 47s - loss: 18.3908 - binary_acc: 0.9453 - val_loss: 23.5734 - val_binary_acc: 0.9249 - 47s/epoch - 249ms/step\n",
            "Epoch 88/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.545 vs 0.563\n",
            "Error rate: 0.578 vs 0.567\n",
            "187/187 - 50s - loss: 18.4286 - binary_acc: 0.9449 - val_loss: 23.3115 - val_binary_acc: 0.9242 - 50s/epoch - 266ms/step\n",
            "Epoch 89/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.565 vs 0.565\n",
            "Error rate: 0.559 vs 0.559\n",
            "187/187 - 50s - loss: 18.3639 - binary_acc: 0.9455 - val_loss: 22.5929 - val_binary_acc: 0.9278 - 50s/epoch - 270ms/step\n",
            "Epoch 90/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.546 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 46s - loss: 18.3160 - binary_acc: 0.9455 - val_loss: 23.0201 - val_binary_acc: 0.9264 - 46s/epoch - 247ms/step\n",
            "Epoch 91/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.580 vs 0.559\n",
            "187/187 - 47s - loss: 18.3930 - binary_acc: 0.9453 - val_loss: 23.1773 - val_binary_acc: 0.9250 - 47s/epoch - 253ms/step\n",
            "Epoch 92/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.565\n",
            "Error rate: 0.572 vs 0.559\n",
            "187/187 - 51s - loss: 18.3732 - binary_acc: 0.9453 - val_loss: 23.0919 - val_binary_acc: 0.9242 - 51s/epoch - 271ms/step\n",
            "Epoch 93/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.541 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 47s - loss: 18.3281 - binary_acc: 0.9454 - val_loss: 23.1819 - val_binary_acc: 0.9243 - 47s/epoch - 250ms/step\n",
            "Epoch 94/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.549 vs 0.565\n",
            "Error rate: 0.580 vs 0.559\n",
            "187/187 - 50s - loss: 18.2085 - binary_acc: 0.9457 - val_loss: 22.8068 - val_binary_acc: 0.9265 - 50s/epoch - 266ms/step\n",
            "Epoch 95/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.518 vs 0.565\n",
            "Error rate: 0.609 vs 0.559\n",
            "187/187 - 46s - loss: 18.1942 - binary_acc: 0.9458 - val_loss: 23.4633 - val_binary_acc: 0.9238 - 46s/epoch - 248ms/step\n",
            "Epoch 96/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.534 vs 0.565\n",
            "Error rate: 0.588 vs 0.559\n",
            "187/187 - 51s - loss: 18.3412 - binary_acc: 0.9454 - val_loss: 23.4858 - val_binary_acc: 0.9237 - 51s/epoch - 271ms/step\n",
            "Epoch 97/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.550 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 47s - loss: 18.3214 - binary_acc: 0.9456 - val_loss: 22.9344 - val_binary_acc: 0.9268 - 47s/epoch - 252ms/step\n",
            "Epoch 98/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.539 vs 0.565\n",
            "Error rate: 0.582 vs 0.559\n",
            "187/187 - 47s - loss: 18.3392 - binary_acc: 0.9455 - val_loss: 23.8286 - val_binary_acc: 0.9217 - 47s/epoch - 252ms/step\n",
            "Epoch 99/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.551 vs 0.565\n",
            "Error rate: 0.572 vs 0.559\n",
            "187/187 - 48s - loss: 18.2205 - binary_acc: 0.9459 - val_loss: 23.7274 - val_binary_acc: 0.9221 - 48s/epoch - 259ms/step\n",
            "Epoch 100/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.531 vs 0.565\n",
            "Error rate: 0.595 vs 0.559\n",
            "187/187 - 47s - loss: 18.1743 - binary_acc: 0.9459 - val_loss: 23.0741 - val_binary_acc: 0.9257 - 47s/epoch - 250ms/step\n",
            "Epoch 101/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.547 vs 0.565\n",
            "Error rate: 0.579 vs 0.559\n",
            "187/187 - 49s - loss: 18.0637 - binary_acc: 0.9464 - val_loss: 23.0547 - val_binary_acc: 0.9253 - 49s/epoch - 264ms/step\n",
            "Epoch 102/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.544 vs 0.565\n",
            "Error rate: 0.582 vs 0.559\n",
            "187/187 - 48s - loss: 18.1924 - binary_acc: 0.9458 - val_loss: 23.1260 - val_binary_acc: 0.9258 - 48s/epoch - 259ms/step\n",
            "Epoch 103/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.530 vs 0.565\n",
            "Error rate: 0.591 vs 0.559\n",
            "187/187 - 47s - loss: 18.2129 - binary_acc: 0.9459 - val_loss: 23.3878 - val_binary_acc: 0.9238 - 47s/epoch - 252ms/step\n",
            "Epoch 104/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.541 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 47s - loss: 18.1483 - binary_acc: 0.9462 - val_loss: 22.9604 - val_binary_acc: 0.9259 - 47s/epoch - 253ms/step\n",
            "Epoch 105/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.558 vs 0.565\n",
            "Error rate: 0.570 vs 0.559\n",
            "187/187 - 48s - loss: 18.0285 - binary_acc: 0.9464 - val_loss: 22.6277 - val_binary_acc: 0.9272 - 48s/epoch - 256ms/step\n",
            "Epoch 106/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.577 vs 0.559\n",
            "187/187 - 48s - loss: 18.1284 - binary_acc: 0.9460 - val_loss: 23.2930 - val_binary_acc: 0.9256 - 48s/epoch - 255ms/step\n",
            "Epoch 107/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.540 vs 0.565\n",
            "Error rate: 0.583 vs 0.559\n",
            "187/187 - 47s - loss: 18.1069 - binary_acc: 0.9462 - val_loss: 23.4170 - val_binary_acc: 0.9245 - 47s/epoch - 254ms/step\n",
            "Epoch 108/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.577 vs 0.559\n",
            "187/187 - 46s - loss: 18.1954 - binary_acc: 0.9462 - val_loss: 23.4889 - val_binary_acc: 0.9238 - 46s/epoch - 248ms/step\n",
            "Epoch 109/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.531 vs 0.565\n",
            "Error rate: 0.588 vs 0.559\n",
            "187/187 - 47s - loss: 18.1728 - binary_acc: 0.9461 - val_loss: 23.8877 - val_binary_acc: 0.9231 - 47s/epoch - 253ms/step\n",
            "Epoch 110/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.565\n",
            "Error rate: 0.566 vs 0.559\n",
            "187/187 - 47s - loss: 18.0661 - binary_acc: 0.9466 - val_loss: 23.4775 - val_binary_acc: 0.9241 - 47s/epoch - 253ms/step\n",
            "Epoch 111/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.557 vs 0.565\n",
            "Error rate: 0.570 vs 0.559\n",
            "187/187 - 52s - loss: 18.1252 - binary_acc: 0.9462 - val_loss: 22.8778 - val_binary_acc: 0.9265 - 52s/epoch - 277ms/step\n",
            "Epoch 112/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.537 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 48s - loss: 18.0835 - binary_acc: 0.9463 - val_loss: 23.6807 - val_binary_acc: 0.9230 - 48s/epoch - 258ms/step\n",
            "Epoch 113/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.552 vs 0.565\n",
            "Error rate: 0.574 vs 0.559\n",
            "187/187 - 50s - loss: 18.0439 - binary_acc: 0.9465 - val_loss: 22.8651 - val_binary_acc: 0.9270 - 50s/epoch - 265ms/step\n",
            "Epoch 114/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 52s - loss: 17.9370 - binary_acc: 0.9468 - val_loss: 23.3412 - val_binary_acc: 0.9246 - 52s/epoch - 277ms/step\n",
            "Epoch 115/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.565\n",
            "Error rate: 0.573 vs 0.559\n",
            "187/187 - 49s - loss: 18.0263 - binary_acc: 0.9462 - val_loss: 22.9944 - val_binary_acc: 0.9243 - 49s/epoch - 263ms/step\n",
            "Epoch 116/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.534 vs 0.565\n",
            "Error rate: 0.587 vs 0.559\n",
            "187/187 - 48s - loss: 17.9816 - binary_acc: 0.9463 - val_loss: 24.0020 - val_binary_acc: 0.9226 - 48s/epoch - 258ms/step\n",
            "Epoch 117/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.546 vs 0.565\n",
            "Error rate: 0.583 vs 0.559\n",
            "187/187 - 49s - loss: 17.9701 - binary_acc: 0.9467 - val_loss: 22.8869 - val_binary_acc: 0.9250 - 49s/epoch - 261ms/step\n",
            "Epoch 118/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.534 vs 0.565\n",
            "Error rate: 0.587 vs 0.559\n",
            "187/187 - 47s - loss: 18.0613 - binary_acc: 0.9463 - val_loss: 23.9981 - val_binary_acc: 0.9216 - 47s/epoch - 254ms/step\n",
            "Epoch 119/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.538 vs 0.565\n",
            "Error rate: 0.585 vs 0.559\n",
            "187/187 - 49s - loss: 17.9612 - binary_acc: 0.9467 - val_loss: 22.7679 - val_binary_acc: 0.9264 - 49s/epoch - 260ms/step\n",
            "Epoch 120/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.558 vs 0.565\n",
            "Error rate: 0.567 vs 0.559\n",
            "187/187 - 48s - loss: 17.9459 - binary_acc: 0.9466 - val_loss: 22.9517 - val_binary_acc: 0.9256 - 48s/epoch - 254ms/step\n",
            "Epoch 121/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.536 vs 0.565\n",
            "Error rate: 0.585 vs 0.559\n",
            "187/187 - 49s - loss: 17.9008 - binary_acc: 0.9469 - val_loss: 24.1463 - val_binary_acc: 0.9223 - 49s/epoch - 261ms/step\n",
            "Epoch 122/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.542 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 47s - loss: 17.9794 - binary_acc: 0.9466 - val_loss: 23.2246 - val_binary_acc: 0.9250 - 47s/epoch - 253ms/step\n",
            "Epoch 123/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.545 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 47s - loss: 18.0748 - binary_acc: 0.9463 - val_loss: 23.3481 - val_binary_acc: 0.9237 - 47s/epoch - 250ms/step\n",
            "Epoch 124/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.558 vs 0.565\n",
            "Error rate: 0.570 vs 0.559\n",
            "187/187 - 51s - loss: 18.0308 - binary_acc: 0.9464 - val_loss: 22.5908 - val_binary_acc: 0.9280 - 51s/epoch - 272ms/step\n",
            "Epoch 125/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.544 vs 0.565\n",
            "Error rate: 0.580 vs 0.559\n",
            "187/187 - 47s - loss: 17.8661 - binary_acc: 0.9472 - val_loss: 23.4537 - val_binary_acc: 0.9235 - 47s/epoch - 254ms/step\n",
            "Epoch 126/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.551 vs 0.565\n",
            "Error rate: 0.572 vs 0.559\n",
            "187/187 - 51s - loss: 17.9139 - binary_acc: 0.9470 - val_loss: 23.2447 - val_binary_acc: 0.9243 - 51s/epoch - 273ms/step\n",
            "Epoch 127/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.549 vs 0.565\n",
            "Error rate: 0.574 vs 0.559\n",
            "187/187 - 47s - loss: 17.9528 - binary_acc: 0.9467 - val_loss: 22.8996 - val_binary_acc: 0.9262 - 47s/epoch - 249ms/step\n",
            "Epoch 128/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.565\n",
            "Error rate: 0.571 vs 0.559\n",
            "187/187 - 49s - loss: 17.7636 - binary_acc: 0.9474 - val_loss: 23.0898 - val_binary_acc: 0.9244 - 49s/epoch - 261ms/step\n",
            "Epoch 129/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.560 vs 0.565\n",
            "Error rate: 0.565 vs 0.559\n",
            "187/187 - 47s - loss: 17.8685 - binary_acc: 0.9470 - val_loss: 23.0556 - val_binary_acc: 0.9248 - 47s/epoch - 251ms/step\n",
            "Epoch 130/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.561 vs 0.565\n",
            "Error rate: 0.564 vs 0.559\n",
            "187/187 - 47s - loss: 17.8331 - binary_acc: 0.9473 - val_loss: 23.1525 - val_binary_acc: 0.9253 - 47s/epoch - 254ms/step\n",
            "Epoch 131/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.565\n",
            "Error rate: 0.568 vs 0.559\n",
            "187/187 - 48s - loss: 17.8855 - binary_acc: 0.9472 - val_loss: 23.0729 - val_binary_acc: 0.9262 - 48s/epoch - 259ms/step\n",
            "Epoch 132/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.555 vs 0.565\n",
            "Error rate: 0.568 vs 0.559\n",
            "187/187 - 48s - loss: 17.8422 - binary_acc: 0.9471 - val_loss: 23.1336 - val_binary_acc: 0.9256 - 48s/epoch - 255ms/step\n",
            "Epoch 133/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.544 vs 0.565\n",
            "Error rate: 0.581 vs 0.559\n",
            "187/187 - 47s - loss: 17.8799 - binary_acc: 0.9471 - val_loss: 23.1982 - val_binary_acc: 0.9245 - 47s/epoch - 252ms/step\n",
            "Epoch 134/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.535 vs 0.565\n",
            "Error rate: 0.588 vs 0.559\n",
            "187/187 - 48s - loss: 17.9168 - binary_acc: 0.9469 - val_loss: 23.5942 - val_binary_acc: 0.9231 - 48s/epoch - 257ms/step\n",
            "Epoch 135/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 48s - loss: 17.8032 - binary_acc: 0.9474 - val_loss: 22.7857 - val_binary_acc: 0.9272 - 48s/epoch - 255ms/step\n",
            "Epoch 136/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.533 vs 0.565\n",
            "Error rate: 0.589 vs 0.559\n",
            "187/187 - 46s - loss: 17.7707 - binary_acc: 0.9474 - val_loss: 23.5621 - val_binary_acc: 0.9242 - 46s/epoch - 248ms/step\n",
            "Epoch 137/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.552 vs 0.565\n",
            "Error rate: 0.572 vs 0.559\n",
            "187/187 - 48s - loss: 17.7804 - binary_acc: 0.9474 - val_loss: 23.0440 - val_binary_acc: 0.9252 - 48s/epoch - 257ms/step\n",
            "Epoch 138/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.537 vs 0.565\n",
            "Error rate: 0.583 vs 0.559\n",
            "187/187 - 47s - loss: 17.8483 - binary_acc: 0.9470 - val_loss: 23.6217 - val_binary_acc: 0.9225 - 47s/epoch - 253ms/step\n",
            "Epoch 139/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.560 vs 0.565\n",
            "Error rate: 0.565 vs 0.559\n",
            "187/187 - 49s - loss: 17.8192 - binary_acc: 0.9475 - val_loss: 22.7334 - val_binary_acc: 0.9270 - 49s/epoch - 262ms/step\n",
            "Epoch 140/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.562 vs 0.565\n",
            "Error rate: 0.563 vs 0.559\n",
            "187/187 - 47s - loss: 17.8593 - binary_acc: 0.9474 - val_loss: 22.8856 - val_binary_acc: 0.9261 - 47s/epoch - 251ms/step\n",
            "Epoch 141/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.537 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 49s - loss: 17.7158 - binary_acc: 0.9476 - val_loss: 23.7391 - val_binary_acc: 0.9243 - 49s/epoch - 263ms/step\n",
            "Epoch 142/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.542 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 48s - loss: 17.7947 - binary_acc: 0.9474 - val_loss: 22.8219 - val_binary_acc: 0.9276 - 48s/epoch - 254ms/step\n",
            "Epoch 143/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.548 vs 0.565\n",
            "Error rate: 0.575 vs 0.559\n",
            "187/187 - 48s - loss: 17.7258 - binary_acc: 0.9473 - val_loss: 23.3830 - val_binary_acc: 0.9242 - 48s/epoch - 259ms/step\n",
            "Epoch 144/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.532 vs 0.565\n",
            "Error rate: 0.593 vs 0.559\n",
            "187/187 - 48s - loss: 17.7145 - binary_acc: 0.9476 - val_loss: 23.3068 - val_binary_acc: 0.9245 - 48s/epoch - 256ms/step\n",
            "Epoch 145/1000\n",
            "63/63 [==============================] - 2s 28ms/step\n",
            "F-measure: 0.543 vs 0.565\n",
            "Error rate: 0.581 vs 0.559\n",
            "187/187 - 51s - loss: 17.7671 - binary_acc: 0.9474 - val_loss: 22.9581 - val_binary_acc: 0.9259 - 51s/epoch - 274ms/step\n",
            "Epoch 146/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.542 vs 0.565\n",
            "Error rate: 0.578 vs 0.559\n",
            "187/187 - 47s - loss: 17.8238 - binary_acc: 0.9471 - val_loss: 23.0611 - val_binary_acc: 0.9252 - 47s/epoch - 250ms/step\n",
            "Epoch 147/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.565\n",
            "Error rate: 0.569 vs 0.559\n",
            "187/187 - 49s - loss: 17.6771 - binary_acc: 0.9477 - val_loss: 23.0462 - val_binary_acc: 0.9245 - 49s/epoch - 260ms/step\n",
            "Epoch 148/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.539 vs 0.565\n",
            "Error rate: 0.583 vs 0.559\n",
            "187/187 - 48s - loss: 17.8252 - binary_acc: 0.9471 - val_loss: 23.6826 - val_binary_acc: 0.9232 - 48s/epoch - 255ms/step\n",
            "Epoch 149/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.542 vs 0.565\n",
            "Error rate: 0.583 vs 0.559\n",
            "187/187 - 47s - loss: 17.6375 - binary_acc: 0.9481 - val_loss: 23.0318 - val_binary_acc: 0.9254 - 47s/epoch - 252ms/step\n",
            "Epoch 150/1000\n",
            "63/63 [==============================] - 2s 25ms/step\n",
            "F-measure: 0.553 vs 0.565\n",
            "Error rate: 0.571 vs 0.559\n",
            "187/187 - 48s - loss: 17.6804 - binary_acc: 0.9476 - val_loss: 23.0635 - val_binary_acc: 0.9257 - 48s/epoch - 257ms/step\n",
            "Epoch 151/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.534 vs 0.565\n",
            "Error rate: 0.592 vs 0.559\n",
            "187/187 - 48s - loss: 17.6471 - binary_acc: 0.9480 - val_loss: 23.0568 - val_binary_acc: 0.9250 - 48s/epoch - 259ms/step\n",
            "Epoch 152/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.556 vs 0.565\n",
            "Error rate: 0.571 vs 0.559\n",
            "187/187 - 47s - loss: 17.6451 - binary_acc: 0.9479 - val_loss: 22.9050 - val_binary_acc: 0.9267 - 47s/epoch - 252ms/step\n",
            "Epoch 153/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.540 vs 0.565\n",
            "Error rate: 0.584 vs 0.559\n",
            "187/187 - 48s - loss: 17.7141 - binary_acc: 0.9476 - val_loss: 23.2778 - val_binary_acc: 0.9238 - 48s/epoch - 256ms/step\n",
            "Epoch 154/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.562 vs 0.565\n",
            "Error rate: 0.563 vs 0.559\n",
            "187/187 - 47s - loss: 17.6266 - binary_acc: 0.9480 - val_loss: 22.8309 - val_binary_acc: 0.9264 - 47s/epoch - 251ms/step\n",
            "Epoch 155/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.545 vs 0.565\n",
            "Error rate: 0.580 vs 0.559\n",
            "187/187 - 49s - loss: 17.7028 - binary_acc: 0.9477 - val_loss: 23.1936 - val_binary_acc: 0.9254 - 49s/epoch - 264ms/step\n",
            "Epoch 156/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.568 vs 0.568\n",
            "Error rate: 0.559 vs 0.559\n",
            "187/187 - 49s - loss: 17.6941 - binary_acc: 0.9476 - val_loss: 22.7279 - val_binary_acc: 0.9267 - 49s/epoch - 264ms/step\n",
            "Epoch 157/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.545 vs 0.568\n",
            "Error rate: 0.581 vs 0.559\n",
            "187/187 - 49s - loss: 17.6496 - binary_acc: 0.9477 - val_loss: 23.0580 - val_binary_acc: 0.9254 - 49s/epoch - 259ms/step\n",
            "Epoch 158/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.568 vs 0.568\n",
            "Error rate: 0.555 vs 0.555\n",
            "187/187 - 51s - loss: 17.5767 - binary_acc: 0.9481 - val_loss: 22.7811 - val_binary_acc: 0.9263 - 51s/epoch - 272ms/step\n",
            "Epoch 159/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.540 vs 0.568\n",
            "Error rate: 0.579 vs 0.555\n",
            "187/187 - 48s - loss: 17.6647 - binary_acc: 0.9476 - val_loss: 23.8402 - val_binary_acc: 0.9224 - 48s/epoch - 257ms/step\n",
            "Epoch 160/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.563 vs 0.568\n",
            "Error rate: 0.562 vs 0.555\n",
            "187/187 - 50s - loss: 17.5916 - binary_acc: 0.9480 - val_loss: 22.6317 - val_binary_acc: 0.9273 - 50s/epoch - 266ms/step\n",
            "Epoch 161/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.550 vs 0.568\n",
            "Error rate: 0.577 vs 0.555\n",
            "187/187 - 48s - loss: 17.5416 - binary_acc: 0.9481 - val_loss: 22.8943 - val_binary_acc: 0.9251 - 48s/epoch - 255ms/step\n",
            "Epoch 162/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.572 vs 0.572\n",
            "Error rate: 0.553 vs 0.553\n",
            "187/187 - 51s - loss: 17.5334 - binary_acc: 0.9480 - val_loss: 22.4630 - val_binary_acc: 0.9279 - 51s/epoch - 275ms/step\n",
            "Epoch 163/1000\n",
            "63/63 [==============================] - 2s 26ms/step\n",
            "F-measure: 0.559 vs 0.572\n",
            "Error rate: 0.566 vs 0.553\n",
            "187/187 - 47s - loss: 17.4418 - binary_acc: 0.9482 - val_loss: 22.6722 - val_binary_acc: 0.9261 - 47s/epoch - 254ms/step\n",
            "Epoch 164/1000\n",
            "63/63 [==============================] - 2s 27ms/step\n",
            "F-measure: 0.562 vs 0.572\n",
            "Error rate: 0.564 vs 0.553\n",
            "187/187 - 50s - loss: 17.6050 - binary_acc: 0.9477 - val_loss: 22.7848 - val_binary_acc: 0.9268 - 50s/epoch - 268ms/step\n",
            "Epoch 165/1000\n"
          ]
        }
      ],
      "source": [
        "# coh_loss = 1.5\n",
        "model.fit(training_generator, validation_data=validation_generator, epochs=1000, callbacks=[MyCustomCallback_44()], verbose=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fJHQG34rIBQD",
        "DjojcnQmR-2P",
        "jQLlRL80RzDC"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}